{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0779440-5f7d-4af3-8ccd-d68d1c2d21d7",
   "metadata": {},
   "source": [
    "# Классификация изображений с эмоциями людей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c3c5eb55-bb55-4911-b297-6116f994ded0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-25T09:16:31.987894Z",
     "iopub.status.busy": "2023-03-25T09:16:31.987894Z",
     "iopub.status.idle": "2023-03-25T09:16:32.003494Z",
     "shell.execute_reply": "2023-03-25T09:16:32.003494Z",
     "shell.execute_reply.started": "2023-03-25T09:16:31.987894Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Version: 2.8.3\n",
      "GPU Device Not Found. Running on CPU\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "print(\"TensorFlow Version:\", tf.__version__)\n",
    "print('GPU Device Found.' if tf.config.list_physical_devices('GPU') else 'GPU Device Not Found. Running on CPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b2604c3-a04f-4ca9-885d-e681e79b824e",
   "metadata": {
    "tags": []
   },
   "source": [
    "# <b>1. ПОДГОТОВКА ДАТАСЕТОВ</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13362b4e-1206-4fc2-aa62-fb51830ac840",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Подготовка файлов для работы с локального диска"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d1f69d2-b87a-4b2b-b21e-48eca5a708b3",
   "metadata": {},
   "source": [
    "### Загрузка данных на локальный диск"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0bc43439-9a0e-43aa-b34d-5db57b39a6b8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-25T09:16:32.003494Z",
     "iopub.status.busy": "2023-03-25T09:16:32.003494Z",
     "iopub.status.idle": "2023-03-25T09:16:38.617471Z",
     "shell.execute_reply": "2023-03-25T09:16:38.615471Z",
     "shell.execute_reply.started": "2023-03-25T09:16:32.003494Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1JdDlgpvtlMN99X0eAruGqXrMNi_sh1sg\n",
      "To: C:\\Users\\Red_Plague\\YandexDisk\\code_learning\\DS_Sber\\Профильный_модуль\\SBER_Diploma\\emotions.zip\n",
      "100%|█████████████████████████████████████| 14.8M/14.8M [00:04<00:00, 3.64MB/s]\n"
     ]
    }
   ],
   "source": [
    "import gdown\n",
    "import zipfile\n",
    "from pathlib import Path\n",
    "\n",
    "# Загрузка архива\n",
    "# stable link https://drive.google.com/file/d/1JdDlgpvtlMN99X0eAruGqXrMNi_sh1sg\n",
    "ident = '1JdDlgpvtlMN99X0eAruGqXrMNi_sh1sg'\n",
    "fname = 'emotions'\n",
    "\n",
    "# Пусть к основной папке с изображениями\n",
    "p = Path('./data')\n",
    "\n",
    "# Путь к базовой директории, которая будет создана чуть позже\n",
    "base_dir = p / fname\n",
    "\n",
    "local_zip = gdown.download(id=ident, output = fname + '.zip')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db6de1fc-f236-4412-ac01-011bf2bc2871",
   "metadata": {},
   "source": [
    "Распаковка в текущую директорию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "96001d55-a3e6-477c-9b6b-6160c9b3f3e7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-25T09:16:38.621472Z",
     "iopub.status.busy": "2023-03-25T09:16:38.620472Z",
     "iopub.status.idle": "2023-03-25T09:16:40.361765Z",
     "shell.execute_reply": "2023-03-25T09:16:40.342764Z",
     "shell.execute_reply.started": "2023-03-25T09:16:38.621472Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[49], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m base_dir \u001b[38;5;241m=\u001b[39m p \u001b[38;5;241m/\u001b[39m fname\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m zipfile\u001b[38;5;241m.\u001b[39mZipFile(local_zip, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m zip_ref:\n\u001b[1;32m----> 8\u001b[0m     \u001b[43mzip_ref\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextractall\u001b[49m\u001b[43m(\u001b[49m\u001b[43mp\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Python\\Python38\\lib\\zipfile.py:1628\u001b[0m, in \u001b[0;36mZipFile.extractall\u001b[1;34m(self, path, members, pwd)\u001b[0m\n\u001b[0;32m   1625\u001b[0m     path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mfspath(path)\n\u001b[0;32m   1627\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m zipinfo \u001b[38;5;129;01min\u001b[39;00m members:\n\u001b[1;32m-> 1628\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_extract_member\u001b[49m\u001b[43m(\u001b[49m\u001b[43mzipinfo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpwd\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Python\\Python38\\lib\\zipfile.py:1681\u001b[0m, in \u001b[0;36mZipFile._extract_member\u001b[1;34m(self, member, targetpath, pwd)\u001b[0m\n\u001b[0;32m   1678\u001b[0m         os\u001b[38;5;241m.\u001b[39mmkdir(targetpath)\n\u001b[0;32m   1679\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m targetpath\n\u001b[1;32m-> 1681\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mopen(member, pwd\u001b[38;5;241m=\u001b[39mpwd) \u001b[38;5;28;01mas\u001b[39;00m source, \\\n\u001b[0;32m   1682\u001b[0m      \u001b[38;5;28mopen\u001b[39m(targetpath, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m target:\n\u001b[0;32m   1683\u001b[0m     shutil\u001b[38;5;241m.\u001b[39mcopyfileobj(source, target)\n\u001b[0;32m   1685\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m targetpath\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Пусть к основной папке с изображениями\n",
    "p = Path('./data')\n",
    "\n",
    "# Путь к базовой директории, которая будет создана чуть позже\n",
    "base_dir = p / fname\n",
    "\n",
    "with zipfile.ZipFile(local_zip, 'r') as zip_ref:\n",
    "    zip_ref.extractall(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b1b87cd-e182-4319-b4de-9ac36e9e704e",
   "metadata": {},
   "source": [
    "Переименуем папку с изображениями в `emotions`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ea34898-6e1e-49a0-b78d-63d354833dd3",
   "metadata": {},
   "source": [
    "Для отключения ограничения \"Только чтение\" у папки с изображениями воспользуемся следующей функцией ([источник](https://www.tutorialspoint.com/How-to-change-the-permission-of-a-directory-using-Python#)):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cad032c-718f-493e-9390-182c31ce7f95",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-03-25T09:16:40.362765Z",
     "iopub.status.idle": "2023-03-25T09:16:40.364765Z",
     "shell.execute_reply": "2023-03-25T09:16:40.364765Z",
     "shell.execute_reply.started": "2023-03-25T09:16:40.364765Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def change_permissions_recursive(path, mode):\n",
    "    for root, dirs, files in os.walk(path, topdown=False):\n",
    "        for dr in [os.path.join(root,d) for d in dirs]:\n",
    "            os.chmod(dr, mode)\n",
    "        for file in [os.path.join(root, f) for f in files]:\n",
    "                os.chmod(file, mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e78cab7-dbdc-48d2-b439-6464fa5d42dd",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-03-25T09:16:40.367766Z",
     "iopub.status.idle": "2023-03-25T09:16:40.368766Z",
     "shell.execute_reply": "2023-03-25T09:16:40.368766Z",
     "shell.execute_reply.started": "2023-03-25T09:16:40.368766Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "zip_content = os.listdir(p)[0]\n",
    "zip_content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee6d68c-19cd-42a8-9010-5e67e4efeff5",
   "metadata": {},
   "source": [
    "Функция не всегда срабатывает с первого раза, поэтому запустим следующий цикл:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f038687-f0a4-4065-9fa9-df65e00e0166",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-03-25T09:16:40.371766Z",
     "iopub.status.idle": "2023-03-25T09:16:40.372766Z",
     "shell.execute_reply": "2023-03-25T09:16:40.372766Z",
     "shell.execute_reply.started": "2023-03-25T09:16:40.372766Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "done = False\n",
    "\n",
    "while done == False:\n",
    "    try:\n",
    "        change_permissions_recursive(p, 0o777)\n",
    "        change_permissions_recursive(p / zip_content, 0o777)\n",
    "        zip_content = os.renames(p / zip_content,\n",
    "                   base_dir)\n",
    "        done = True\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93929814-c990-491f-a5be-a83b80700df9",
   "metadata": {},
   "source": [
    "Теперь загруженный архив можно удалить."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "865cee50-171e-4e05-a230-afce949eee7e",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-03-25T09:16:40.374766Z",
     "iopub.status.idle": "2023-03-25T09:16:40.375766Z",
     "shell.execute_reply": "2023-03-25T09:16:40.375766Z",
     "shell.execute_reply.started": "2023-03-25T09:16:40.375766Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.remove(fname + '.zip')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d7eca90-1b26-4f1e-9829-24bdf98920b1",
   "metadata": {},
   "source": [
    "### Настройка директорий"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb44ea63-3c1a-4202-8139-1b2dc4ef0ed8",
   "metadata": {},
   "source": [
    "Проверим содержимое папки с изображениями, мы должны увидеть список из папок с названиями этих папок и их количество. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a32b0d0-640a-49b3-abb1-926b3d7ae68d",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-03-25T09:16:40.377766Z",
     "iopub.status.idle": "2023-03-25T09:16:40.379766Z",
     "shell.execute_reply": "2023-03-25T09:16:40.378766Z",
     "shell.execute_reply.started": "2023-03-25T09:16:40.378766Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# Базовая директория\n",
    "base_dir = p / fname\n",
    "# # base_dir = '/content/drive/MyDrive/Sber DS/Diploma/data/emotions/'  # for colab\n",
    "classes = os.listdir(base_dir)\n",
    "\n",
    "num_classes = len(classes)\n",
    "\n",
    "# и ее содержимое\n",
    "print(\"Содержимое базовой директории:\")\n",
    "print(classes)\n",
    "print('Количество классов:', num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb40ae68-be6c-47f4-8a57-ed7854e8f9c4",
   "metadata": {},
   "source": [
    "Переименуем папки в необходимые нам названия классов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "398776b4-e4f4-4684-b484-008716e080aa",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-03-25T09:16:40.381766Z",
     "iopub.status.idle": "2023-03-25T09:16:40.383766Z",
     "shell.execute_reply": "2023-03-25T09:16:40.382766Z",
     "shell.execute_reply.started": "2023-03-25T09:16:40.382766Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# class_names = [x.lower() for x in classes]\n",
    "class_names = ['anger', 'disgust', 'fear', 'joyfulness', 'neutral']\n",
    "\n",
    "done = False\n",
    "while done == False:\n",
    "    try:\n",
    "        change_permissions_recursive(base_dir, 0o777)\n",
    "        done = True\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "done = False\n",
    "while done == False:\n",
    "    try:\n",
    "        for i, class_name in enumerate(class_names):\n",
    "            change_permissions_recursive(base_dir/class_name, 0o777)\n",
    "            os.renames(base_dir/classes[i], base_dir/class_name)\n",
    "        done = True\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "classes = os.listdir(base_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef5aaec9-cad4-4c3e-8f85-5ba4aefcb92d",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-03-25T09:16:40.385767Z",
     "iopub.status.idle": "2023-03-25T09:16:40.386767Z",
     "shell.execute_reply": "2023-03-25T09:16:40.386767Z",
     "shell.execute_reply.started": "2023-03-25T09:16:40.386767Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b65756c-63f0-4ba2-b58d-8cb890a4c121",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Удалим некорректные файлы"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c85e4b-d0be-4b6c-be6a-71a36cc669c2",
   "metadata": {},
   "source": [
    "Если в архиве содержатся некорректные (\"битые\") файлы, то мы получим ошибку на том или ином этапе обучения и подготовки модели к переносу на мобильное устройство. Код ниже позволяет обнаружить и сразу удалить такие файлы при их наличии. Запустим эту функцию для всех папок с классами ([источник кода](https://github.com/tensorflow/datasets/issues/2188))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc7eaccc-201e-4526-ac0f-384e426c0fb6",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-03-25T09:16:40.388767Z",
     "iopub.status.idle": "2023-03-25T09:16:40.390767Z",
     "shell.execute_reply": "2023-03-25T09:16:40.389767Z",
     "shell.execute_reply.started": "2023-03-25T09:16:40.389767Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from tensorflow.io import read_file\n",
    "from tensorflow.image import decode_image\n",
    "\n",
    "def delete_corrupted_files(folder, base_dir):\n",
    "    for image in sorted((base_dir / f'{folder}').glob('*')):\n",
    "        try:\n",
    "            img = read_file(str(image))\n",
    "            img = decode_image(img)\n",
    "\n",
    "            if img.ndim != 3:\n",
    "                print(f\"[FILE_CORRUPT] {str(image).split('/')[-1]} DELETED\")\n",
    "                image.unlink()\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"[ERR] {str(image).split('/')[-1]}: {e} DELETED\")\n",
    "            image.unlink()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f027da06-5033-452c-b0d1-b82a73d60ffb",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-03-25T09:16:40.393767Z",
     "iopub.status.idle": "2023-03-25T09:16:40.394767Z",
     "shell.execute_reply": "2023-03-25T09:16:40.394767Z",
     "shell.execute_reply.started": "2023-03-25T09:16:40.394767Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for folder in classes:\n",
    "    print(folder)\n",
    "    delete_corrupted_files(folder, base_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c8b1b04-b745-49b2-a733-bcea1c4b9c86",
   "metadata": {},
   "source": [
    "Битых файлов нет, можно двигаться дальше.\n",
    "\n",
    "Сохраним пути к субдиректориям с классами в отдельные переменные и посмотрим на конечное количество изображений в каждом классе."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b1bc8b7-037f-4aa1-8648-6d58bd605792",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-03-25T09:16:40.396767Z",
     "iopub.status.idle": "2023-03-25T09:16:40.398767Z",
     "shell.execute_reply": "2023-03-25T09:16:40.397767Z",
     "shell.execute_reply.started": "2023-03-25T09:16:40.397767Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "anger_dir, disgust_dir, fear_dir, joyfulness_dir, neutral_dir = [base_dir / classes[i]\n",
    "                                                   for i in range(len(classes))]\n",
    "directories = anger_dir, disgust_dir, fear_dir, joyfulness_dir, neutral_dir\n",
    "\n",
    "\n",
    "anger_fnames, disgust_fnames, fear_fnames, joyfulness_fnames, neutral_fnames = [os.listdir(i)\n",
    "                                                              for i in directories]\n",
    "files_names = anger_fnames, disgust_fnames, fear_fnames, joyfulness_fnames, neutral_fnames\n",
    "\n",
    "\n",
    "for i, cls_name in enumerate(class_names):\n",
    "    print(cls_name + ':', len(files_names[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b0f39d-7b54-4d72-aad4-938faa544e51",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-03-25T09:16:40.400767Z",
     "iopub.status.idle": "2023-03-25T09:16:40.401767Z",
     "shell.execute_reply": "2023-03-25T09:16:40.400767Z",
     "shell.execute_reply.started": "2023-03-25T09:16:40.400767Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "x = np.array([len(anger_fnames), len(disgust_fnames),\n",
    "              len(fear_fnames), len(joyfulness_fnames),\n",
    "              len(neutral_fnames)])\n",
    "\n",
    "plt.title('Распределение количества изображений по классам')\n",
    "plt.pie(x, labels=classes, autopct='%.1f%%');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c08c4b34-0bfa-4018-843a-7ac7a9e54fb5",
   "metadata": {},
   "source": [
    "Классы несбалансированы, поэтому, помимо метрики `accuracy`, для оценки ошибки классификации мы будем использовать матрицу ошибок. \n",
    "\n",
    "Посмотрим на названия отдельных файлов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c61efe6a-d8e7-4b89-b2af-f3adb64f9f78",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-03-25T09:16:40.403768Z",
     "iopub.status.idle": "2023-03-25T09:16:40.405768Z",
     "shell.execute_reply": "2023-03-25T09:16:40.404768Z",
     "shell.execute_reply.started": "2023-03-25T09:16:40.404768Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e684ce-2f46-4730-bebc-1d4cc8252eb4",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-03-25T09:16:40.407768Z",
     "iopub.status.idle": "2023-03-25T09:16:40.408768Z",
     "shell.execute_reply": "2023-03-25T09:16:40.408768Z",
     "shell.execute_reply.started": "2023-03-25T09:16:40.408768Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i, j in zip(class_names, files_names):\n",
    "    print(i, j[90:93])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8631b194-fe32-47f3-89da-8db3822c5eca",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Визуализация оригинальных изображений"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eac120c8-7c81-4b57-91bd-fde0e4ace677",
   "metadata": {},
   "source": [
    "Посмотрим на фотографии из обеих субдиректорий - по 4 фотографии каждого класса."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d81fc74-287e-4e2b-a151-c188b179ef10",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-03-25T09:16:40.410768Z",
     "iopub.status.idle": "2023-03-25T09:16:40.412768Z",
     "shell.execute_reply": "2023-03-25T09:16:40.412768Z",
     "shell.execute_reply.started": "2023-03-25T09:16:40.412768Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Параметры для отрисовки - количество строк и столбцов\n",
    "nrows = 5\n",
    "ncols = 4\n",
    "\n",
    "# Индекс для итерации изображений\n",
    "pic_index = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f615fe2-ba7e-4eb5-bd3b-b176cf6cf15d",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-03-25T09:16:40.414768Z",
     "iopub.status.idle": "2023-03-25T09:16:40.416768Z",
     "shell.execute_reply": "2023-03-25T09:16:40.415768Z",
     "shell.execute_reply.started": "2023-03-25T09:16:40.415768Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Запустите эту ячейку несколько раз, чтобы увидеть разные наборы фотографий\n",
    "\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(ncols*4, nrows*4)\n",
    "\n",
    "pic_index += 4\n",
    "\n",
    "next_anger_pic = [os.path.join(anger_dir, fname)\n",
    "                for fname in anger_fnames[pic_index-4:pic_index]]\n",
    "next_disgust_pic = [os.path.join(disgust_dir, fname)\n",
    "                for fname in disgust_fnames[pic_index-4:pic_index]]\n",
    "next_fear_pic = [os.path.join(fear_dir, fname)\n",
    "                for fname in fear_fnames[pic_index-4:pic_index]]\n",
    "next_joyfulness_pic = [os.path.join(joyfulness_dir, fname)\n",
    "                for fname in joyfulness_fnames[pic_index-4:pic_index]]\n",
    "next_neutral_pic = [os.path.join(neutral_dir, fname)\n",
    "                for fname in neutral_fnames[pic_index-4:pic_index]]\n",
    "\n",
    "\n",
    "for i, img_path in enumerate(next_anger_pic+next_disgust_pic+\n",
    "                            next_fear_pic+next_joyfulness_pic+\n",
    "                            next_neutral_pic):\n",
    "    ax = plt.subplot(nrows, ncols, i+1)\n",
    "    ax.axis(False)\n",
    "    plt.title(img_path)\n",
    "    \n",
    "    img = mpimg.imread(img_path)\n",
    "    plt.imshow(img)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d2301b-9412-4d8d-a14b-9ad61bb414c6",
   "metadata": {},
   "source": [
    "Изображения в имеющихся наборах имеют различное разрешение и соотношение сторон, их необходимо привести к единому стандарту на стадии формирования датасетов для нейронной сети. Этим мы сейчас и займемся."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d028475-14e1-4a32-92b0-a3be8fd6290b",
   "metadata": {},
   "source": [
    "## Создание датасетов под данную предобученную модель"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8678bc29-5484-4e5c-8afe-3547d5540f37",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Split изображений"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd456ca6-22bc-4b3b-876d-e109866b9f25",
   "metadata": {},
   "source": [
    "Так как готовых инструментов для формирования датасета из трех частей (тренировка, валидация, тест) в tensorflow нет, предварительно необходимо разделить все изображения на соответствующие директории, внутри которых будут папки с классами.\n",
    "\n",
    "Напишем собственную функцию, которая переместит все изображения по нужным нам папкам, создав, таким образом, необходимое разделение данных на три датасета. Функция содержит вложенную функцию `split_numbers`, которая автоматически определит количество изображений, необходимое для каждого сплита по всем классам в соотношении: `train : validation : test = 8:1:1` (значение по умолчанию). Однако при необходимости это соотношение можно изменить в любую сторону, для этого нужно указать значения для тренировочной и валидационной частей, тестовая часть посчитается автоматически как остаток (при этом нужно помнить, что сумма частей, на которые мы делим датасает, должна быть кратна 10; при желании это правило можно изменить, переписав вложенную функцию)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f986714-b02b-44d0-997b-eab134b20a57",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-03-25T09:16:40.419768Z",
     "iopub.status.idle": "2023-03-25T09:16:40.420769Z",
     "shell.execute_reply": "2023-03-25T09:16:40.420769Z",
     "shell.execute_reply.started": "2023-03-25T09:16:40.420769Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "def make_split(files_names, base_dir, class_folder, relation=(8, 1)):\n",
    "    \n",
    "    dataset_split_folders = 'train', 'validation', 'test'\n",
    "    train_dir, val_dir, test_dir = [base_dir / i\n",
    "                    for i in dataset_split_folders]\n",
    "\n",
    "    for directory in (train_dir, val_dir, test_dir):\n",
    "        try:\n",
    "            Path.mkdir(directory)\n",
    "        except:\n",
    "            # print(f'Directory {directory} already exists or cannot be created.')\n",
    "            pass\n",
    "        try:\n",
    "            Path.mkdir(directory / class_folder)\n",
    "        except:\n",
    "            # print(f'Directory {directory / class_folder} already exists or cannot be created.')\n",
    "            pass\n",
    "\n",
    "    def split_numbers(files_names=files_names):\n",
    "        imgs_num = len(files_names)\n",
    "        train_num, val_num = int(imgs_num//10*relation[0]), int(imgs_num//10*relation[1])\n",
    "        test_num = imgs_num - train_num - val_num\n",
    "        return train_num, val_num, test_num\n",
    "        \n",
    "    examples = split_numbers(files_names)\n",
    "    directories = train_dir, val_dir, test_dir\n",
    "\n",
    "    for num, dr in zip(examples, directories):\n",
    "        i = num\n",
    "        while i != 0:\n",
    "            image_name = os.listdir(base_dir / class_folder)[i-1]\n",
    "            shutil.move(base_dir / class_folder / image_name,\n",
    "                         dr / class_folder / image_name)\n",
    "            i -= 1\n",
    "\n",
    "    shutil.rmtree(base_dir / class_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25d49840-85db-4694-bb62-e99058896e40",
   "metadata": {},
   "source": [
    "Применим эту функцию к каждому из классов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc6ff1ef-311b-46f9-8a28-ed977383f4e8",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-03-25T09:16:40.422769Z",
     "iopub.status.idle": "2023-03-25T09:16:40.423769Z",
     "shell.execute_reply": "2023-03-25T09:16:40.423769Z",
     "shell.execute_reply.started": "2023-03-25T09:16:40.423769Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i in range(len(classes)):\n",
    "    make_split(files_names[i],\n",
    "             base_dir=base_dir,\n",
    "             class_folder=classes[i],\n",
    "             # изменим немного соотношение в пользу валидации\n",
    "             relation=(8, 1.2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a0590b-bf33-479a-8e48-7f42b4139679",
   "metadata": {
    "tags": []
   },
   "source": [
    "Наш датасет разделен на три части в соотношении 8:1:1. Теперь у нас имеются три директории, содержащие папки с нужными нам классами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c019f3e-8ef0-4853-a114-ec8af71c65d5",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-03-25T09:16:40.426769Z",
     "iopub.status.idle": "2023-03-25T09:16:40.427769Z",
     "shell.execute_reply": "2023-03-25T09:16:40.426769Z",
     "shell.execute_reply.started": "2023-03-25T09:16:40.426769Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i in os.listdir(base_dir):\n",
    "    print(i, os.listdir(base_dir / i))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b543193a-1fed-4562-a3fb-c47c92b3ae1e",
   "metadata": {},
   "source": [
    "### Предобученная модель | MobileNet V2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "705ee255-ba58-4fc5-bad5-40654b509a30",
   "metadata": {},
   "source": [
    "Для нашей задачи в рамках данной части дипломной работы мы будем использовать предобученную модель `MobileNet V2`, которая отличается от первой версии гораздо меньшим количеством параметров при сохранении высоких предсказательных способностей, что критично для имплементации моделей на мобильные устройства. \n",
    "\n",
    "Модель разработана в корпорации \"Google\" и обучена на основе 1,4 млн. изображений для 1000 классов. Это позволяет нам надеяться на то, что мы сможем дообучить нашу модель с небольшим количеством изображений до приемлемого уровня точности, 80%.\n",
    "\n",
    "В библиотеке TensorFlow существует как минимум два способа использования предобученных моделей:\n",
    "- использованием библиотеки моделей `tensorflow-hub`,\n",
    "- с использованием модуля Keras `tf.keras.applications`.\n",
    "\n",
    "Первый способ проще в имплементации и очень хорошо годится для производства, однако у него есть существенный недостаток для разработчика - предобученные модели поставляются как единый слой и не подлежат частичной разморозке, разморозить можно только все слои зараз, отчего важным становится правильный выбор версии данной модели (`MobileNet V2` в первом случае рассматривается как семейство моделей). Также два способа отличаются методом `rescale` - в первом случае изображения необходимо привести к стандарту [0, 1], тогда как во втором - [-1, 1]. Это необходимо иметь ввиду при подготовке наших изображений перед отправкой на обучение.\n",
    "\n",
    "Воспользуемся вторым способом, так как он гораздо более пластичен для тонкой настройки и позволяет экспениментировать с гиперпараметрами. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c850248-8e30-4e03-affa-7a55e2c34a53",
   "metadata": {},
   "source": [
    "### Гиперпараметры для модели с переносом обучения"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80c95e4e-39a5-440f-b77f-61c8434c29cd",
   "metadata": {},
   "source": [
    "В самом начале обозначим гиперпараметры для будущей модели, это позволит нам уже сейчас начать подготавливать необходимые команды с этими данными для дальнейшего использования. \n",
    "\n",
    "`MobileNet V2` позволяет выбрать любое разрешение выше 32х32, мы будем использовать разрешение 224х224. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb2758f-3c5d-456c-96db-511ac5747531",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-03-25T09:16:40.429769Z",
     "iopub.status.idle": "2023-03-25T09:16:40.430769Z",
     "shell.execute_reply": "2023-03-25T09:16:40.429769Z",
     "shell.execute_reply.started": "2023-03-25T09:16:40.429769Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "MODULE_HANDLE = 'tf.keras.applications.InceptionResNetV2'\n",
    "IMAGE_SIZE = (224, 224)\n",
    "IMG_SHAPE = IMAGE_SIZE + (3,)\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "print(f\"Используем {MODULE_HANDLE}, входное разрешение: {IMAGE_SIZE}, размер батча: {BATCH_SIZE}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54f531a2-0925-4fa3-8962-1c9608b05803",
   "metadata": {},
   "source": [
    "### Создание датасетов | `image_dataset_from_directory`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f9729f8-a080-4977-bb87-2b6368b3f42f",
   "metadata": {},
   "source": [
    "Для обучения модели и затем конвертации ее в облегченную версию все предварительно разделенные по папкам изображения необходимо перевести в формат `dataset`. Для выполнения этой задачи будем использовать метод библиотеки `keras` `image_dataset_from_directory`. В качестве `label_mode` установим `categorical` для перевода лейблов в вид `one_hot_encoding`.\n",
    "\n",
    "Для корректной работы кода, создающего облегченную версию нашей модели, который мы позаимствовали из курса по компьютерному зрению, тренировочный и валидационный датасеты должны иметь достаточно большой батч, тогда как тестовый датасет должен выдавать по одному изображению зараз, то есть батч должен равняться 1. \n",
    "\n",
    "Весь необходимый код оформим в функцию, которая и проделает все операции."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e671aa-38a4-428e-8d56-ab81b50970dd",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-03-25T09:16:40.431769Z",
     "iopub.status.idle": "2023-03-25T09:16:40.432769Z",
     "shell.execute_reply": "2023-03-25T09:16:40.432769Z",
     "shell.execute_reply.started": "2023-03-25T09:16:40.432769Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "def datasets_prep(base_directory=base_dir,\n",
    "                  seed=123,\n",
    "                  batch_size=BATCH_SIZE,\n",
    "                  image_size=IMAGE_SIZE, \n",
    "                  label_mode='categorical'):\n",
    "    \n",
    "    train_dir = base_dir / 'train'\n",
    "    val_dir = base_dir / 'validation'\n",
    "    test_dir = base_dir / 'test'\n",
    "    \n",
    "    train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "                            train_dir,\n",
    "                            label_mode=label_mode,\n",
    "                            seed=seed,\n",
    "                            image_size=IMAGE_SIZE,\n",
    "                            batch_size=batch_size)\n",
    "    \n",
    "    val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "                            val_dir,\n",
    "                            label_mode=label_mode,\n",
    "                            seed=seed,\n",
    "                            image_size=IMAGE_SIZE,\n",
    "                            batch_size=batch_size)\n",
    "    \n",
    "    test_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "                            test_dir,\n",
    "                            label_mode=label_mode,\n",
    "                            seed=seed,\n",
    "                            image_size=IMAGE_SIZE,\n",
    "                            batch_size=1)  # установим батч = 1\n",
    "    \n",
    "    return train_ds, val_ds, test_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d504b3-e759-4585-bff6-ec7a02f4b8d4",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-03-25T09:16:40.435769Z",
     "iopub.status.idle": "2023-03-25T09:16:40.436769Z",
     "shell.execute_reply": "2023-03-25T09:16:40.436769Z",
     "shell.execute_reply.started": "2023-03-25T09:16:40.435769Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_batches, validation_batches, test_batches = datasets_prep()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "065096cd-5fdd-4ff2-adbd-26d3f21e90c2",
   "metadata": {},
   "source": [
    "Проверим созданные датасеты на соответствие заданным выше параметрам."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6111e6e-2f0b-4875-a5a6-4311662c83bb",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-03-25T09:16:40.438770Z",
     "iopub.status.idle": "2023-03-25T09:16:40.439770Z",
     "shell.execute_reply": "2023-03-25T09:16:40.439770Z",
     "shell.execute_reply.started": "2023-03-25T09:16:40.439770Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for ds in (train_batches, validation_batches, test_batches):\n",
    "    for image_batch, label_batch in ds.take(1):\n",
    "        print(image_batch.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e09aff9b-0f7c-401d-9a20-1e8137ab306d",
   "metadata": {},
   "source": [
    "Как и требовалось, тренировочный и валидационный датасеты содержат в батче установленное количество изображений, тестовый - 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33489e59-74d4-4ef2-8df9-30356dc3ed0d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-06T16:59:18.718298Z",
     "iopub.status.busy": "2023-03-06T16:59:18.717300Z",
     "iopub.status.idle": "2023-03-06T16:59:18.736288Z",
     "shell.execute_reply": "2023-03-06T16:59:18.733290Z",
     "shell.execute_reply.started": "2023-03-06T16:59:18.718298Z"
    }
   },
   "source": [
    "Проверим классы, верно ли отработал данный инструмент."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d86250-0f0d-4e9d-a51a-5ca23ab6ac03",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-03-25T09:16:40.442770Z",
     "iopub.status.idle": "2023-03-25T09:16:40.443770Z",
     "shell.execute_reply": "2023-03-25T09:16:40.442770Z",
     "shell.execute_reply.started": "2023-03-25T09:16:40.442770Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for ds in (train_batches, validation_batches, test_batches):\n",
    "    print(ds.class_names)\n",
    "\n",
    "class_names = train_batches.class_names\n",
    "num_classes = len(class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f311d45-03e7-46cd-a0d3-87417c75be92",
   "metadata": {},
   "source": [
    "### Визуализация изображений из `train_batches`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73dabb8e-91bc-4c6a-80ea-56ca50a971af",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-03-25T09:16:40.445770Z",
     "iopub.status.idle": "2023-03-25T09:16:40.446770Z",
     "shell.execute_reply": "2023-03-25T09:16:40.446770Z",
     "shell.execute_reply.started": "2023-03-25T09:16:40.446770Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "for images, labels in train_batches.take(10):\n",
    "    for i in range(16):\n",
    "        ax = plt.subplot(4, 4, i+1)\n",
    "        plt.imshow(images[i].numpy().astype('uint8'))\n",
    "        category_class = int(tf.argmax(labels[i]))\n",
    "        plt.title(class_names[category_class])\n",
    "        plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e74bff9-4531-4008-8359-302eb0f02da5",
   "metadata": {},
   "source": [
    "Также возьмем одно из изображений из получившегося датасета и посмотрим, получили ли мы желаемое разрешение. Это изображение пригодится нам в дальнейшм, поэтому сохраним его в переменную `one_pic`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d802fb31-4757-48d4-b12f-5f8f8c516597",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-03-25T09:16:40.448770Z",
     "iopub.status.idle": "2023-03-25T09:16:40.449770Z",
     "shell.execute_reply": "2023-03-25T09:16:40.448770Z",
     "shell.execute_reply.started": "2023-03-25T09:16:40.448770Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# одно случайное изображение\n",
    "for images, labels in train_batches.take(30):\n",
    "    one_pic = images[1].numpy()\n",
    "    label = labels[1]\n",
    "    break\n",
    "\n",
    "print(one_pic.shape)\n",
    "plt.figure(figsize=(4, 4))\n",
    "plt.title(class_names[int(tf.argmax(label))])\n",
    "plt.axis('off')\n",
    "plt.imshow(one_pic.astype('uint8'));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e25045bd-f4af-416e-802e-82a5048e1dd6",
   "metadata": {},
   "source": [
    "Итак, датасет для модели создан, все фотографии приведены к единому разрешению, можно переходить к обработке данных для тренировки модели. Обработка данных для нашей модели состоит из двух частей: нормализация значений массива (`rescale`) и агументация данных. Подготовим обе части и запустим две модели - без аугментации и с ней, чтобы посмотреть, как этот блок слоев влияет на работу модели. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "871d6ff3-3850-44fc-88e7-946b1d66f61d",
   "metadata": {
    "tags": []
   },
   "source": [
    "# <b>2. ПОДГОТОВКА ФУНКЦИЙ И ПЕРЕМЕННЫХ ДЛЯ ОБУЧЕНИЯ</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca60f2fa-5f0b-4342-aa11-3fa74a68f6ef",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Слои для препроцессинга изображений"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc529770-3839-47ac-90eb-2668d471d1fe",
   "metadata": {},
   "source": [
    "### Rescale"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ec8421-f6bd-4d26-9489-4c8b9ec9585e",
   "metadata": {},
   "source": [
    "Стандартизация значений матриц изображений - обязательная операция, если мы хотим получить хорошие результаты по работе нашей сети. Для использования данной предобученной модели значения матриц изображений необходимо отшкалировать по стандарту от -1 до 1 (именно такой стандарт использовался для обучения этой сети). Есть два способа создания соответствующего слоя:\n",
    "\n",
    "```python\n",
    "preprocess_input = tf.keras.applications.mobilenet_v2.preprocess_input\n",
    "\n",
    "или\n",
    "\n",
    "rescale = tf.keras.layers.Rescaling(1./127.5, offset=-1)\n",
    "```\n",
    "\n",
    "Мы возьмем второй вариант, так как он более пластичен."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19cb9b8d-4a46-4d2d-b2f7-38e820a32d42",
   "metadata": {},
   "source": [
    "Данный слой будет первым в моделях, поэтому необходимо указать `input_shape` входных изображений."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d27f827b-9e7b-41c4-bab1-7d0d3496b285",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-03-25T09:16:40.452770Z",
     "iopub.status.idle": "2023-03-25T09:16:40.453770Z",
     "shell.execute_reply": "2023-03-25T09:16:40.453770Z",
     "shell.execute_reply.started": "2023-03-25T09:16:40.453770Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "rescale = tf.keras.Sequential([\n",
    "        tf.keras.layers.Rescaling(1./127.5, offset=-1,\n",
    "                                  input_shape=IMAGE_SIZE + (3,),\n",
    "                                  name='Rescaling')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b100d864-9bb0-4308-835d-6ccdefb2d709",
   "metadata": {},
   "source": [
    "Проверим качество работы слоя на фотографии, которую мы использовали выше."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4cbce83-ce99-4893-bf4f-578e25e512d8",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-03-25T09:16:40.455771Z",
     "iopub.status.idle": "2023-03-25T09:16:40.456771Z",
     "shell.execute_reply": "2023-03-25T09:16:40.456771Z",
     "shell.execute_reply.started": "2023-03-25T09:16:40.456771Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.ops.numpy_ops import np_config\n",
    "np_config.enable_numpy_behavior()\n",
    "\n",
    "# увеличим размерность изображения до 4, так иначе оно не пройдет\n",
    "# корректно через слой\n",
    "result_for_rescale = rescale(np.expand_dims(one_pic, axis=0))\n",
    "# print(result_for_rescale.shape)\n",
    "\n",
    "# вернем результату размерность 3 для отображения\n",
    "result = np.squeeze(result_for_rescale)\n",
    "# print(result.shape)\n",
    "\n",
    "plt.figure(figsize=(4, 4))\n",
    "plt.axis('off')\n",
    "plt.imshow(result)\n",
    "\n",
    "# print(\"Picture's shape:\", result.shape)\n",
    "print(\"Минимальное и максимальное значение пикселей:\", result.min(), result.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e78daaa0-6f16-4c9f-b288-4d5069870414",
   "metadata": {},
   "source": [
    "Слой отработал ожидаемым образом, при этом видно, что изменился контраст изображения. Это нормально, так как значения матрицы изображений были растянуты по обе стороны от 0. В любом случае, алгоритм обнаруживает зависимости не по внешнему виду картинок, а исходя из численных значений матриц изображений, контраст имеет значение только для нашего, человеческого глаза."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3136ab1-6f81-48c5-a261-dc07bb6efb13",
   "metadata": {},
   "source": [
    "### Аугментация данных"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fba0a6d-dccb-4426-9d8a-714b297e8476",
   "metadata": {},
   "source": [
    "Так как наш датасет создан из сравнительно небольшого набора данных, то для избежания переобучения мы воспользуемся всеми доступными возможностями библиотеки `keras`, в частности, добавим в модель слои агументации, которые искусственным образом увеличат количество изображений через внешнее изменение имеющихся. \n",
    "\n",
    "Создадим последовательность слоев `RandomFlip` (зеркальное отображение изображения в случайном порядке), `RandomRotation` (поворот изображения по часовой стрелке на случайный угол), `RandomZoom` (увеличение и уменьшение изображения в случайном порядке), а также `RandomContrast`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6edaea35-2d25-43d9-a543-3a27220b9401",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-03-25T09:16:40.459771Z",
     "iopub.status.idle": "2023-03-25T09:16:40.460771Z",
     "shell.execute_reply": "2023-03-25T09:16:40.460771Z",
     "shell.execute_reply.started": "2023-03-25T09:16:40.460771Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_aug = tf.keras.Sequential([\n",
    "    tf.keras.layers.RandomFlip('horizontal_and_vertical', name='RandomFlip'),\n",
    "    tf.keras.layers.RandomRotation(factor=1, fill_mode='reflect',\n",
    "                                   name='RandomRotation'),\n",
    "    tf.keras.layers.RandomZoom(height_factor=(-0.1, 0.3), name='RandomZoom'),\n",
    "    # tf.keras.layers.RandomContrast(factor=(0.1, 0.1), name='RandomContrast')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebaabd13-2002-4413-af2f-70038238ee16",
   "metadata": {},
   "source": [
    "Как и в случае с созданием датасета, проверим на уже использованном изображении из тренировочного датасета, как работает последовательность по аугментации данных. Если следующий блок с кодом запустить несколько раз, то мы увидим, как меняется изображение, проходя через вышеописанные слои.\n",
    "\n",
    "> _**Note**: В версии tf 2.11.0 при выполнении нижеследующего кода выводятся предупреждения, которые не влияют на качество работы модели._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ef0bb5-4665-4690-84f5-e919a8250530",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-03-25T09:16:40.462771Z",
     "iopub.status.idle": "2023-03-25T09:16:40.463771Z",
     "shell.execute_reply": "2023-03-25T09:16:40.463771Z",
     "shell.execute_reply.started": "2023-03-25T09:16:40.463771Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.ops.numpy_ops import np_config\n",
    "np_config.enable_numpy_behavior()\n",
    "\n",
    "# увеличим размерность изображения до 4, так иначе оно не пройдет\n",
    "# корректно через последовательность слоев\n",
    "result_for_aug = np.expand_dims(result, axis=0)\n",
    "augmented = data_aug(result_for_aug).numpy()\n",
    "# print(augmented.shape)\n",
    "\n",
    "plt.axis('off')\n",
    "\n",
    "# вернем результату размерность 3 для отображения\n",
    "plt.imshow(np.squeeze(augmented));\n",
    "\n",
    "print(\"Минимальное и максимальное значение пикселей:\", augmented.min(), augmented.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4d30d5c-1073-408b-9f7c-ff5f5d93aed0",
   "metadata": {},
   "source": [
    "Видим, что некоторые каналы из-за усиления контрастности дают выжженные пиксели. Эта особенность будет выправлена следующей операцией - `rescale`, которая при приведении значений к стандарту [-1, 1] также влияет на контраст. В итоге мы получим более менее нормализованную картинку. При желании слой с контрастом, как и другие слои аугментации, всегда можно отключить или изменить параметры, но нас устраивает такой результат."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95caf714-3d7c-4775-b251-36eddbf71269",
   "metadata": {},
   "source": [
    "Итак, обе последовательности вполне успешно справляются с поставленными перед ними задачами. Переходим к созданию и обучению моделей."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0e4d2a4-f02a-4174-ae17-12db9250a9cf",
   "metadata": {},
   "source": [
    "## Архитектура, компиляция, обучение модели"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff3ec0f-d307-4f4c-adbe-17fad6909ff7",
   "metadata": {},
   "source": [
    "`DROPOUT_RATE` назначим небольшим, так как датасет у нас скромный по объему, и, если мы будем исключать значительную часть датасета из обучения, модель просто не сможет обучаться.\n",
    "\n",
    "Также назначим переменную базовый learning rate - `BASE_LR`, установим значение на 0.01. Мы будем использовать специальный инструмент `callbacks`, который при необходимости будет уменьшать данный параметр непосредственно в ходе обучения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9181a282-7630-4d44-a9cd-6d02e8291e95",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-03-25T09:16:40.466771Z",
     "iopub.status.idle": "2023-03-25T09:16:40.467771Z",
     "shell.execute_reply": "2023-03-25T09:16:40.466771Z",
     "shell.execute_reply.started": "2023-03-25T09:16:40.466771Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "DROPOUT_RATE = 0.1\n",
    "BASE_LR = 0.01\n",
    "REGULARIZER=tf.keras.regularizers.L1L2(l1=0.0, l2=0.5)\n",
    "EPOCHS=500  # см. callbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1ce151f-59a9-4f16-879d-1128e447fbf9",
   "metadata": {},
   "source": [
    "Также пропишем дополнительную метрику для наших  несбалансированных мультиклассов - PR-AUC с использованием precision и recall. PR-AUC - это площадь под графиком этих двух метрик, позволяет учесть данные по редким классам и получить более объективную картину об эффективности обучения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6aed728-cb61-432e-a215-587cdd0dbdea",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-03-25T09:16:40.469771Z",
     "iopub.status.idle": "2023-03-25T09:16:40.470771Z",
     "shell.execute_reply": "2023-03-25T09:16:40.470771Z",
     "shell.execute_reply.started": "2023-03-25T09:16:40.470771Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "curve = 'PR'\n",
    "name = curve+'_AUC'\n",
    "AUC = tf.keras.metrics.AUC(curve=curve, multi_label=False, name=name)\n",
    "\n",
    "metrics = ['accuracy', AUC]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b8db2a3-8478-40f4-8702-e8c0e4493aa6",
   "metadata": {},
   "source": [
    "### Callbacks - контроль остановки обучения и `learning_rate`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b0cc8f3-70df-4a47-acb4-f12646e8a054",
   "metadata": {},
   "source": [
    "Так как обучение моделей по компьютерному зрению очень затратно по ресурсам, а мы планируем провести целый ряд различных экспериментов, для снижения нагрузки на систему мы будем использовать так называемые `callbacks` - специальные модули `keras`, которые позволяют в автомтическом режиме контролировать, когда следует вносить те или иные изменения в обучение. Мы будем использовать два вида `callbacks`:\n",
    "\n",
    "- `EarlyStopping` для ранней остановки обучения при прекращении сокращения `val_loss` (для нашего несбалансированного датасета этот показатель важнее, чем непоказательный для несбалансированных классов `val_accuracy`),\n",
    "\n",
    "- `ReduceLROnPlateau` для уменьшения `learning rate` при ухудшении показателей `val_loss` (Исследователями обнаружено, что постепенное снижение `learning rate` в процессе обучения положительно сказывается на качестве обучения, что мы увидим на наших экспериментах, см. список использованных источников и литературы Holbrook R. \"Intro to Deep Learning\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "711e4561-1c64-4677-9b56-f7babdbff09c",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-03-25T09:16:40.472772Z",
     "iopub.status.idle": "2023-03-25T09:16:40.473772Z",
     "shell.execute_reply": "2023-03-25T09:16:40.473772Z",
     "shell.execute_reply.started": "2023-03-25T09:16:40.473772Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import callbacks\n",
    "\n",
    "early_stopping = callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    min_delta=0.001,  # минимальное значение для зачета улучшения\n",
    "    patience=20,  # количество эпох с плохим результатом перед остановкой\n",
    "    restore_best_weights=True,  # восстановить лучшие показатели модели\n",
    ")\n",
    "\n",
    "lr_schedule = callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    patience=1,\n",
    "    factor=0.5,  # на какое значение будет умножаться текущий lr\n",
    "    min_lr=1e-8,  # минимальное значение lr\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d848437-47a6-42c2-8010-8c744a9a7f65",
   "metadata": {},
   "source": [
    "Таким образом, наши callbacks создают следующий алгоритм: \n",
    "- при ухудшении `val_loss` на данной эпохе следующая эпоха будет прходить с `learning rate` в два раза ниже,\n",
    "- если `val_loss` ухудшается 15 раз кряду, обучение прекращается.\n",
    "\n",
    "Все эти параметры можно регулировать и подбирать, для наших задач мы остановимся на этих гиперпараметрах, так как они нас устраивают."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12e95c25-6e0b-4a49-a8a7-104690bbf4da",
   "metadata": {},
   "source": [
    "## Визуализация итогов обучения"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "057d1ec3-0429-4c9e-adda-248bec5eb52a",
   "metadata": {},
   "source": [
    "### Функция потерь и метрики"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c70c618c-e5a9-463a-943b-3bda3da62bf0",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-03-25T09:16:40.475772Z",
     "iopub.status.idle": "2023-03-25T09:16:40.476772Z",
     "shell.execute_reply": "2023-03-25T09:16:40.475772Z",
     "shell.execute_reply.started": "2023-03-25T09:16:40.475772Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def val_acc_viz(history, epochs, loss_from=1):\n",
    "    '''\n",
    "    Функция отрисовывает историю функции потерь и\n",
    "    используемых метрик. Аргументы:\n",
    "    - history - данные истории обучения,\n",
    "    - epochs - количество эпох для отображения,\n",
    "    - loss_from - с какой эпохи отображать loss.\n",
    "    '''\n",
    "    acc = history.history['accuracy']\n",
    "    val_acc = history.history['val_accuracy']\n",
    "\n",
    "    auc = history.history[name]\n",
    "    val_auc = history.history['val_' + name]\n",
    "\n",
    "    loss = history.history['loss'][loss_from-1:]\n",
    "    val_loss = history.history['val_loss'][loss_from-1:]\n",
    "\n",
    "    epochs_range = range(1, len(acc)+1)\n",
    "\n",
    "    sns.set_style('whitegrid')\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.plot(range(loss_from, len(acc)+1), loss, label='Training Loss')\n",
    "    plt.plot(range(loss_from, len(acc)+1), val_loss, label='Validation Loss')\n",
    "    plt.legend(loc='best')\n",
    "    plt.title('Loss')\n",
    "    plt.xlabel('epochs')\n",
    "    # plt.show()\n",
    "\n",
    "    # plt.figure(figsize=(8, 5))\n",
    "    # ax1 = plt.subplot(1, 2, 1)\n",
    "    ax2 = plt.subplot(1, 3, 2)\n",
    "    plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "    plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "    plt.legend(loc='best')\n",
    "    plt.title('Accuracy')\n",
    "    plt.xlabel('epochs')\n",
    "\n",
    "    # plt.subplot(1, 2, 2, sharey=ax1)\n",
    "    plt.subplot(1, 3, 3, sharey=ax2)\n",
    "    plt.plot(epochs_range, auc, label='Training ' + name)\n",
    "    plt.plot(epochs_range, val_auc, label='Validation ' + name)\n",
    "    plt.legend(loc='best')\n",
    "    plt.title(name)\n",
    "    plt.xlabel('epochs')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d36d8d97-71dc-4230-85a9-6e42839aa4b4",
   "metadata": {},
   "source": [
    "### Функция матрицы ошибок"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f89014-cfe2-4653-9e38-f43bffe354ac",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-03-25T09:16:40.478772Z",
     "iopub.status.idle": "2023-03-25T09:16:40.479772Z",
     "shell.execute_reply": "2023-03-25T09:16:40.479772Z",
     "shell.execute_reply.started": "2023-03-25T09:16:40.479772Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def confusion_matrix(model, images_number=None, dataset=test_batches, class_names=class_names):\n",
    "\n",
    "    '''\n",
    "    Выводит матрицу ошибок на тестовых данных. \n",
    "    \n",
    "    Аргументы:\n",
    "    - model - обученная модель.\n",
    "    - images_number - количество изображений из тестовой выборки;\n",
    "            если None, то используются все изображения в выборке.\n",
    "    - dataset - tf.dataset с тестовыми изображениями.\n",
    "    '''\n",
    "    \n",
    "    from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "    \n",
    "    if images_number is None:\n",
    "        test_images = dataset\n",
    "    else:\n",
    "        test_images = dataset.take(images_number)\n",
    "        \n",
    "    y_test, y_pred = ([np.argmax(y) for _, y in test_images], \n",
    "                      [np.argmax(x) for x in model.predict(test_images)])\n",
    "        \n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)\n",
    "    disp.plot(cmap='GnBu')\n",
    "    # disp.plot(cmap='afmhot')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2bd38ad-b5e1-43ac-b2d9-e80f8e299257",
   "metadata": {},
   "source": [
    "Для торча."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9255d853-7040-4c48-a667-cf71be5cbb5d",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-03-25T09:16:40.481772Z",
     "iopub.status.idle": "2023-03-25T09:16:40.483772Z",
     "shell.execute_reply": "2023-03-25T09:16:40.482772Z",
     "shell.execute_reply.started": "2023-03-25T09:16:40.482772Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def confusion_matrix_torch(model, dataset, class_names=class_names):\n",
    "\n",
    "    '''\n",
    "    Выводит матрицу ошибок на тестовых данных. \n",
    "    \n",
    "    Аргументы:\n",
    "    - model - обученная модель.\n",
    "    - dataset - torch dataloader с тестовыми изображениями.\n",
    "    '''\n",
    "    \n",
    "    from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "        \n",
    "    y_test, y_pred = ([np.argmax(y) for _, y in dataset], \n",
    "                      [np.argmax(x) for x in model.predict(dataset)])\n",
    "        \n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)\n",
    "    disp.plot()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f845ca6d-b08c-47f8-883d-c1aa5783c92a",
   "metadata": {},
   "source": [
    "## Предсказания отдельных изображений"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92af1bb6-5913-4b8e-a1e8-69cc901a56c6",
   "metadata": {},
   "source": [
    "### На изображениях из Сети"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c2e0da2-2999-4b5a-843d-583a5ce71903",
   "metadata": {},
   "source": [
    "При желании качество работы модели можно проверить на реальных фотографиях экспертным методом. Для этого создадим новую папку, куда загрузим желаемые изображения. Далее, подготовленная функция преобразует изображения в необходимый для визуализации и предсказания формат. Оставим эту часть в качестве дополнения, использовать ее пока не будем."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7938237-bc43-46b0-a786-c346179d5d96",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-03-25T09:16:40.485772Z",
     "iopub.status.idle": "2023-03-25T09:16:40.486772Z",
     "shell.execute_reply": "2023-03-25T09:16:40.486772Z",
     "shell.execute_reply.started": "2023-03-25T09:16:40.486772Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from PIL import Image\n",
    "# import numpy as np\n",
    "# from tensorflow.keras.utils import load_img, img_to_array\n",
    "# import os\n",
    "\n",
    "# new_test_dir = Path('./data/test_images')\n",
    "# Path.mkdir(new_test_dir)\n",
    "\n",
    "# def show_predictions(model):\n",
    "    \n",
    "#     images = os.listdir(new_test_dir)\n",
    "    \n",
    "#     for i, img_path in enumerate(images):\n",
    "\n",
    "#         # путь к тестовым изображениям\n",
    "#         path = new_test_dir / img_path\n",
    "\n",
    "#         # приведение изображений к желаемому разрешению\n",
    "#         img = load_img(path, target_size=IMAGE_SIZE + (3,))\n",
    "#         # перевод изображения в массив\n",
    "#         x = img_to_array(img)\n",
    "\n",
    "#         # добавление четвертого измерения для модели\n",
    "#         images = np.expand_dims(x, axis=0)\n",
    "        \n",
    "#         plt.figure(figsize=(2, 2))\n",
    "#         # Отключить оси\n",
    "#         plt.axis(False)\n",
    "#         plt.imshow(np.squeeze(images).astype('uint8'))\n",
    "#         # plt.title(img_path)\n",
    "#         plt.show()\n",
    "\n",
    "#         # предсказание\n",
    "#         classes = model.predict(images, batch_size=10)\n",
    "\n",
    "#         class_pred = np.argmax(classes)\n",
    "#         # print(np.argmax(class_pred))\n",
    "#         print(f'{img_path} is {class_names[class_pred]} ({np.max(classes[0])*100:.2f}%)')\n",
    "        \n",
    "# show_predictions(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2a750aa-ed17-4f9b-91cd-feef2697d147",
   "metadata": {},
   "source": [
    "### На изображениях из тестовой выборки"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f87971-5960-4707-a98b-b631e69e9182",
   "metadata": {},
   "source": [
    "Посмотрим на то, как модель предсказывает тестовые изображения, хранящиеся в третьей, тестовой выборке, которая до этого момента не принимала участия в работе. Напомним, что тестовая выбора разбита на батчи по одному изображению, что позволяет нам проще контролировать количество изображений, которое мы хотим использовать для предсказания. Следующая функция покажет изображение, заданное и предсказанное значение класса, а также \"уверенность\" модели в своем предсказании. На данном этапе посмотрим на небольшое количество изображений (по умолчанию 10, можно изменить это число, задав соответствующий аргумент), а полную картину оценим дальше, построив матрицу ошибок."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee4bae1-ff36-4818-ae4f-9b4f5c5b70b8",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-03-25T09:16:40.488772Z",
     "iopub.status.idle": "2023-03-25T09:16:40.489773Z",
     "shell.execute_reply": "2023-03-25T09:16:40.489773Z",
     "shell.execute_reply.started": "2023-03-25T09:16:40.489773Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.utils import load_img, img_to_array\n",
    "import os\n",
    "\n",
    "def show_predictions(model, image_set=test_batches,\n",
    "                     images_number=10, visualization=False):\n",
    "\n",
    "    images = image_set.take(images_number)\n",
    "\n",
    "    for img, label in images:\n",
    "\n",
    "        if visualization == True:\n",
    "            plt.figure(figsize=(2, 2))\n",
    "            # Отключить оси\n",
    "            plt.axis(False)\n",
    "            # оставим три измерения из четырех\n",
    "            image = np.squeeze(img)\n",
    "            plt.imshow(image.astype('uint8'))\n",
    "            plt.show()\n",
    "\n",
    "        # реальный класс\n",
    "        label = np.argmax(label)\n",
    "        # предсказанный класс\n",
    "        prediction = model.predict(img)\n",
    "        pred = np.argmax(prediction)\n",
    "\n",
    "        print(f'{class_names[label]} is {class_names[pred]} ({np.max(prediction[0])*100:.2f}%)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4867bc87-6fa2-4eee-8628-359f9fbaa63e",
   "metadata": {},
   "source": [
    "## Оптимизация работы кэша"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "244edd5e-dbcd-4afa-9abd-c757598df7be",
   "metadata": {},
   "source": [
    "Оптимизируем работу кэша следующим кодом:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79708f01-f599-4547-a0ec-b2ccf952d358",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-03-25T09:16:40.492773Z",
     "iopub.status.idle": "2023-03-25T09:16:40.493773Z",
     "shell.execute_reply": "2023-03-25T09:16:40.492773Z",
     "shell.execute_reply.started": "2023-03-25T09:16:40.492773Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_batches = train_batches.cache().prefetch(buffer_size=1)\n",
    "validation_batches = validation_batches.cache().prefetch(buffer_size=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0639070-3d34-4812-814b-91ee3bbc9af8",
   "metadata": {
    "tags": []
   },
   "source": [
    "# <b>Эксперимент 0 | Оптимизаторы и лосс</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3572c78-1406-4036-afe1-8a299afcc350",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-03-25T09:16:40.498773Z",
     "iopub.status.idle": "2023-03-25T09:16:40.499773Z",
     "shell.execute_reply": "2023-03-25T09:16:40.499773Z",
     "shell.execute_reply.started": "2023-03-25T09:16:40.499773Z"
    }
   },
   "outputs": [],
   "source": [
    "stat_0 = dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9a764dc-3b46-4cfe-b100-5df56eba8fa6",
   "metadata": {},
   "source": [
    "## <b>Модель 0.5 | RMSprop, MSE</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f9ff4c7-67c6-499e-89e7-18784a54f47b",
   "metadata": {},
   "source": [
    "### Архитектура модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab9e3c8-5cdc-42b6-a2ac-245ece18b4ec",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-03-25T09:16:40.501773Z",
     "iopub.status.idle": "2023-03-25T09:16:40.503773Z",
     "shell.execute_reply": "2023-03-25T09:16:40.502773Z",
     "shell.execute_reply.started": "2023-03-25T09:16:40.502773Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "strides = 2\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "\n",
    "            rescale,\n",
    "            data_aug,\n",
    "\n",
    "            tf.keras.layers.Conv2D(32, (3, 3), padding=\"same\",\n",
    "                               strides=2, activation='relu'),\n",
    "            tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "            tf.keras.layers.Conv2D(64, (3, 3), padding=\"same\",\n",
    "                               strides=strides, activation='relu'),\n",
    "            tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "            tf.keras.layers.Conv2D(64, (3, 3), padding=\"same\",\n",
    "                               strides=strides, activation='relu'),\n",
    "            tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "            tf.keras.layers.Conv2D(32, (3, 3), padding=\"same\",\n",
    "                               strides=strides, activation='relu'),\n",
    "\n",
    "            tf.keras.layers.Flatten(),\n",
    "    \n",
    "            tf.keras.layers.Dropout(DROPOUT_RATE),\n",
    "            tf.keras.layers.BatchNormalization(),\n",
    "            tf.keras.layers.Dense(64, activation='relu'),\n",
    "    \n",
    "            tf.keras.layers.BatchNormalization(),\n",
    "            tf.keras.layers.Dense(num_classes, activation='softmax',\n",
    "                                 kernel_regularizer=REGULARIZER\n",
    "                                 )\n",
    "\n",
    "], name='RMSprop_mse')\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f663fe-4fef-411a-a9a1-9a460ca8af09",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-03-25T09:16:40.505773Z",
     "iopub.status.idle": "2023-03-25T09:16:40.506773Z",
     "shell.execute_reply": "2023-03-25T09:16:40.506773Z",
     "shell.execute_reply.started": "2023-03-25T09:16:40.506773Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(model.trainable_variables)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "563071bc-2121-4cbf-8d81-22fbe60726bc",
   "metadata": {},
   "source": [
    "### Компиляция"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c09455-49e7-40e7-97b5-8bd33ec67058",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-03-25T09:16:40.508774Z",
     "iopub.status.idle": "2023-03-25T09:16:40.509774Z",
     "shell.execute_reply": "2023-03-25T09:16:40.509774Z",
     "shell.execute_reply.started": "2023-03-25T09:16:40.509774Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.RMSprop(learning_rate=BASE_LR),\n",
    "              loss='mse',\n",
    "              metrics=metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c8b9aa4-988b-4647-bcd2-fbf6c0d908c2",
   "metadata": {},
   "source": [
    "### Обучение модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d00631fc-9940-4255-aa5e-b838389dc1d9",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-03-25T09:16:40.511774Z",
     "iopub.status.idle": "2023-03-25T09:16:40.513774Z",
     "shell.execute_reply": "2023-03-25T09:16:40.512774Z",
     "shell.execute_reply.started": "2023-03-25T09:16:40.512774Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "hist = model.fit(train_batches,\n",
    "                 epochs=EPOCHS,\n",
    "                 validation_data=validation_batches,\n",
    "                 callbacks=[early_stopping, lr_schedule])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2668406f-7dbe-452c-9890-b534c4e382ca",
   "metadata": {},
   "source": [
    "### Визуализация данных по работе алгоритма"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57fb0635-c0af-4c8e-a4e0-18b4199f6d88",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-03-25T09:16:40.515774Z",
     "iopub.status.idle": "2023-03-25T09:16:40.516774Z",
     "shell.execute_reply": "2023-03-25T09:16:40.516774Z",
     "shell.execute_reply.started": "2023-03-25T09:16:40.516774Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "val_acc_viz(hist, len(hist.history['accuracy']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f49bbc8-b598-4a84-a13b-3faea8291fed",
   "metadata": {},
   "source": [
    "### Предсказание модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "181664b6-cdc2-458d-a27f-2928ef343a14",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-03-25T09:16:40.518774Z",
     "iopub.status.idle": "2023-03-25T09:16:40.520774Z",
     "shell.execute_reply": "2023-03-25T09:16:40.519774Z",
     "shell.execute_reply.started": "2023-03-25T09:16:40.519774Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "show_predictions(model, visualization=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a4f64e-3d6e-4f4a-88af-5da1b2aaed77",
   "metadata": {},
   "source": [
    "### Матрица ошибок"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "084d3bd4-175c-4ac6-98b1-695c3ea6538f",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-03-25T09:16:40.522774Z",
     "iopub.status.idle": "2023-03-25T09:16:40.523774Z",
     "shell.execute_reply": "2023-03-25T09:16:40.523774Z",
     "shell.execute_reply.started": "2023-03-25T09:16:40.523774Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "confusion_matrix(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "674ec7af-f48a-4680-8c99-0ae3fb636eee",
   "metadata": {},
   "source": [
    "### Вывод"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8377207-cfae-4a30-99be-c09e1e5e7bac",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-03-25T09:16:40.525775Z",
     "iopub.status.idle": "2023-03-25T09:16:40.526775Z",
     "shell.execute_reply": "2023-03-25T09:16:40.526775Z",
     "shell.execute_reply.started": "2023-03-25T09:16:40.526775Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "val_acc_best = np.max(hist.history['val_accuracy'])\n",
    "val_auc_best = np.max(hist.history['val_PR_AUC'])\n",
    "model_best_results = round(val_acc_best, 2), round(val_auc_best, 2)\n",
    "\n",
    "print(f'val_accuracy: {model_best_results[0]}')\n",
    "print(f'val_PR_AUC: {model_best_results[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e3e8e3a-9d77-42d0-82ad-2ff7981315e0",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-03-25T09:16:40.529775Z",
     "iopub.status.idle": "2023-03-25T09:16:40.530775Z",
     "shell.execute_reply": "2023-03-25T09:16:40.530775Z",
     "shell.execute_reply.started": "2023-03-25T09:16:40.530775Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# сохраним данные о модели\n",
    "model_05 = model\n",
    "hist_05 = hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "456792c7-82b5-4265-a05f-ff37e21e9c21",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-03-25T09:16:40.532775Z",
     "iopub.status.idle": "2023-03-25T09:16:40.533775Z",
     "shell.execute_reply": "2023-03-25T09:16:40.533775Z",
     "shell.execute_reply.started": "2023-03-25T09:16:40.533775Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "stat_0['RMSprop_mse'] = model_best_results[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56275138-e5c0-4a31-934b-a8f558fda8f7",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-03-25T09:16:40.535775Z",
     "iopub.status.idle": "2023-03-25T09:16:40.536775Z",
     "shell.execute_reply": "2023-03-25T09:16:40.536775Z",
     "shell.execute_reply.started": "2023-03-25T09:16:40.535775Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "stat_0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c327938a-88c9-428e-ac19-c7ec7170cbf1",
   "metadata": {
    "tags": []
   },
   "source": [
    "# <b>МОДЕЛЬ 1</b> | `Include_top`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b81fc50-ee7a-43b2-a2eb-1bcf23b5081d",
   "metadata": {},
   "source": [
    "## Модуль `tf.keras.applications` | `feature_extractor_layer`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d76a0fd6-656b-48ca-84bc-024f4835e03c",
   "metadata": {},
   "source": [
    "Создадим `feature_extractor`, который извлечет веса из предобученной модели `tensorflow` для переноса обучения на нашу модель. При переносе обучения рекомендуется отключать самые \"верхние\", то есть последние слои предобученной модели: именно в них происходит обучение на данную классификацию. Однако для начала мы проверим, как будут обучаться наши модели на полной предобученной модели `Mobile Net V2`.\n",
    "\n",
    "Во втором блоке экспериментов мы отключим верхние слои, а в третьем пойдем еще дальше и разморозим часть слоев предобученной модели. За \"разморозку\" слоев у нас будет отвечать параметр `do_fine_tuning`, который может принимать только булевы значения (в первых двух блоках он установлен в режим `False`).\n",
    "\n",
    "Итак, приступим к первому блоку экспериментов, используем предобученную модель \"как есть\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3939e6cc-5f50-456f-b578-0663d3a08f0e",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-03-25T09:16:40.538775Z",
     "iopub.status.idle": "2023-03-25T09:16:40.539775Z",
     "shell.execute_reply": "2023-03-25T09:16:40.538775Z",
     "shell.execute_reply.started": "2023-03-25T09:16:40.538775Z"
    }
   },
   "outputs": [],
   "source": [
    "do_fine_tuning = False\n",
    "feature_extractor = do_fine_tuning = False\n",
    "feature_extractor = tf.keras.applications.InceptionResNetV2(\n",
    "                                                include_top=True,\n",
    "                                                weights=\"imagenet\",\n",
    "                                                # input_tensor=None,\n",
    "                                                input_shape=IMG_SHAPE,\n",
    "                                                # pooling=None,\n",
    "                                                # classes=1000,\n",
    "                                                classifier_activation=None,\n",
    "                                                # **kwargs\n",
    "                                                )\n",
    "feature_extractor.trainable = do_fine_tuning\n",
    "\n",
    "print(f'Разморозка слоев: {do_fine_tuning}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d76e2da-d20d-4522-b8ea-f00662d78a1a",
   "metadata": {},
   "source": [
    "## <b>Модель 1.3</b> | Dropout и BatchNormalization layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48678e34-253a-420c-9095-5230e63cf1df",
   "metadata": {},
   "source": [
    "Доработаем предыдущую модель, добавив в ее архитектуру аугментацию данных и слои батч-нормализации и `dropout`. Это позволит нам отложить момент переобучения."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b251d9cf-667d-4b93-96b9-34040fc42bdf",
   "metadata": {},
   "source": [
    "### Архитектура модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dab5f7f-6566-4d9d-b5b7-1795d43a96b3",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-03-25T09:16:40.540775Z",
     "iopub.status.idle": "2023-03-25T09:16:40.541775Z",
     "shell.execute_reply": "2023-03-25T09:16:40.541775Z",
     "shell.execute_reply.started": "2023-03-25T09:16:40.541775Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(f'Строим модель на базе {MODULE_HANDLE}.')\n",
    "print(f'Разморозка слоев: {do_fine_tuning}.\\n')\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "\n",
    "            rescale,\n",
    "            data_aug,\n",
    "\n",
    "            feature_extractor,\n",
    "\n",
    "#             tf.keras.layers.Dropout(DROPOUT_RATE),\n",
    "#             tf.keras.layers.BatchNormalization(),\n",
    "#             tf.keras.layers.Dense(512, activation='relu'),\n",
    "\n",
    "#             tf.keras.layers.Dropout(DROPOUT_RATE),\n",
    "#             tf.keras.layers.BatchNormalization(),\n",
    "#             tf.keras.layers.Dense(1024, activation='relu'),\n",
    "\n",
    "#             tf.keras.layers.Dropout(DROPOUT_RATE),\n",
    "#             tf.keras.layers.BatchNormalization(),\n",
    "#             tf.keras.layers.Dense(1024, activation='relu'),\n",
    "\n",
    "#             tf.keras.layers.Dropout(DROPOUT_RATE),\n",
    "#             tf.keras.layers.BatchNormalization(),\n",
    "            tf.keras.layers.Dense(num_classes, activation='softmax')\n",
    "\n",
    "], name='include_top')\n",
    "\n",
    "model.build(input_shape=(None,) + IMAGE_SIZE + (3,))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fbafba0-aabd-44f2-8f1d-954a620d6908",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-03-25T09:16:40.543776Z",
     "iopub.status.idle": "2023-03-25T09:16:40.544776Z",
     "shell.execute_reply": "2023-03-25T09:16:40.544776Z",
     "shell.execute_reply.started": "2023-03-25T09:16:40.544776Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(model.trainable_variables)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78c19ed7-359a-4512-962c-e0e410bc2179",
   "metadata": {},
   "source": [
    "### Компиляция"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a48704f-0bdd-4ccb-9ac1-48354b95670c",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-03-25T09:16:40.546776Z",
     "iopub.status.idle": "2023-03-25T09:16:40.547776Z",
     "shell.execute_reply": "2023-03-25T09:16:40.547776Z",
     "shell.execute_reply.started": "2023-03-25T09:16:40.547776Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=BASE_LR),\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "              metrics=metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "578f22a1-6add-40b1-a630-9755d2f2c4ff",
   "metadata": {},
   "source": [
    "### Обучение модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8484eaf-1cce-46fb-b03a-5b416b0fba05",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-03-25T09:16:40.549776Z",
     "iopub.status.idle": "2023-03-25T09:16:40.550776Z",
     "shell.execute_reply": "2023-03-25T09:16:40.550776Z",
     "shell.execute_reply.started": "2023-03-25T09:16:40.550776Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "hist = model.fit(train_batches,\n",
    "                 epochs=EPOCHS,\n",
    "                 validation_data=validation_batches,\n",
    "                 callbacks=[early_stopping, lr_schedule]\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57af181d-cce3-494d-bdc8-03c94076eb7b",
   "metadata": {},
   "source": [
    "### Визуализация данных по работе алгоритма"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e38cb30-9260-4659-8dd3-479fe52c2a80",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-03-25T09:16:40.553776Z",
     "iopub.status.idle": "2023-03-25T09:16:40.554776Z",
     "shell.execute_reply": "2023-03-25T09:16:40.553776Z",
     "shell.execute_reply.started": "2023-03-25T09:16:40.553776Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "val_acc_viz(hist, len(hist.history['accuracy']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5af6018-fc64-41d4-b9a0-21ada0c7f919",
   "metadata": {},
   "source": [
    "### Предсказание модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff66824-626e-4d60-a2a4-c89959d14339",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-03-25T09:16:40.556776Z",
     "iopub.status.idle": "2023-03-25T09:16:40.557776Z",
     "shell.execute_reply": "2023-03-25T09:16:40.557776Z",
     "shell.execute_reply.started": "2023-03-25T09:16:40.557776Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "show_predictions(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faeefc72-f205-4e98-a08b-bcd046c85c0a",
   "metadata": {},
   "source": [
    "### Матрица ошибок"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c6be51b-a322-4ed0-af9e-82a6e2b6d5e8",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-03-25T09:16:40.559777Z",
     "iopub.status.idle": "2023-03-25T09:16:40.560777Z",
     "shell.execute_reply": "2023-03-25T09:16:40.560777Z",
     "shell.execute_reply.started": "2023-03-25T09:16:40.560777Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "confusion_matrix(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "976f5b8a-8667-4c12-ad56-7f6d994d5bf7",
   "metadata": {},
   "source": [
    "### Вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "686f1fe4-e15d-4356-a5f4-68bdf3dc94f4",
   "metadata": {},
   "source": [
    "Модель очень быстро переобучилась, практически с первых эпох, при этом и ее предсказательная способность значительно выросла. Анализ матрицы ошибок показывает, что лучше всего модель предсказывает класс `neutral`, что неудивительно, так как именно в данном классе у нас больше всего изображений. Зафиксируем лучший показатель `val_accuracy` и сохраним данные по результатам работы модели в отдельные переменные на случай, если потребуется к ним снова обратиться."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b30fb3-2329-45e1-8881-3a78e6080d03",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-03-25T09:16:40.562777Z",
     "iopub.status.idle": "2023-03-25T09:16:40.564777Z",
     "shell.execute_reply": "2023-03-25T09:16:40.563777Z",
     "shell.execute_reply.started": "2023-03-25T09:16:40.563777Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "val_acc_best = np.max(hist.history['val_accuracy'])\n",
    "model_1_3_best_result = round(val_acc_best, 2)\n",
    "model_1_3_best_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d5d626-523b-4276-a743-d74859cb62f6",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-03-25T09:16:40.566777Z",
     "iopub.status.idle": "2023-03-25T09:16:40.567777Z",
     "shell.execute_reply": "2023-03-25T09:16:40.567777Z",
     "shell.execute_reply.started": "2023-03-25T09:16:40.567777Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# сохраним данные о модели\n",
    "model_1_3 = model\n",
    "hist_1_3 = hist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fdf4a92-457f-4831-8658-3407ccaf115d",
   "metadata": {},
   "source": [
    "# <b>МОДЕЛЬ 3</b> | `fine_tuning`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddde05ff-9751-4989-bd9c-10496e0e2230",
   "metadata": {},
   "source": [
    "# <b>Модель 3.1</b> | Pretrained baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd600fc-cf69-4ce5-923e-e7c1d1fb3fcf",
   "metadata": {},
   "source": [
    "## Модуль `tf.keras.applications` | `feature_extractor_layer`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5e56911-71f3-4955-919c-efe205990cb8",
   "metadata": {},
   "source": [
    "Попробуем предолеть проблему переобучения, добавив к предыдущей архитектуре слои с аугментацией данных, которые мы подготовили заранее. Другие параметры оставим нетронутыми. Обратим внимание, что мы создаем новую модель, а не дообучаем предыдущую (дообучением мы займемся позже)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36bbb3b2-1c85-42ab-9be3-7524efb45424",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-03-25T09:16:40.569777Z",
     "iopub.status.idle": "2023-03-25T09:16:40.570777Z",
     "shell.execute_reply": "2023-03-25T09:16:40.570777Z",
     "shell.execute_reply.started": "2023-03-25T09:16:40.570777Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# do_fine_tuning = False\n",
    "# feature_extractor = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE,\n",
    "#                                                include_top=False,\n",
    "#                                                weights='imagenet')\n",
    "# feature_extractor.trainable = do_fine_tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "774104a3-6350-4ebe-bdf9-8cf73ba7b24a",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-03-25T09:16:40.573777Z",
     "iopub.status.idle": "2023-03-25T09:16:40.574777Z",
     "shell.execute_reply": "2023-03-25T09:16:40.573777Z",
     "shell.execute_reply.started": "2023-03-25T09:16:40.573777Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# do_fine_tuning = False\n",
    "# feature_extractor = tf.keras.applications.MobileNet(\n",
    "#                                                 input_shape=IMG_SHAPE,\n",
    "#                                                 # alpha=1.0,\n",
    "#                                                 # depth_multiplier=1,\n",
    "#                                                 dropout=DROPOUT_RATE,\n",
    "#                                                 include_top=False,\n",
    "#                                                 weights=\"imagenet\",\n",
    "#                                                 # input_tensor=None,\n",
    "#                                                 # pooling=None,\n",
    "#                                                 # classes=1000,\n",
    "#                                                 classifier_activation='softmax',\n",
    "#                                                 # **kwargs\n",
    "# )\n",
    "# feature_extractor.trainable = do_fine_tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c4ce04-cee2-4125-85ad-ba09b7dab225",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-03-25T09:16:40.576777Z",
     "iopub.status.idle": "2023-03-25T09:16:40.577778Z",
     "shell.execute_reply": "2023-03-25T09:16:40.576777Z",
     "shell.execute_reply.started": "2023-03-25T09:16:40.576777Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# do_fine_tuning = False\n",
    "# feature_extractor = tf.keras.applications.InceptionV3(\n",
    "#                                                 include_top=False,\n",
    "#                                                 weights=\"imagenet\",\n",
    "#                                                 # input_tensor=None,\n",
    "#                                                 input_shape=IMG_SHAPE,\n",
    "#                                                 # pooling=None,\n",
    "#                                                 # classes=1000,\n",
    "#                                                 # classifier_activation=\"softmax\",\n",
    "# )\n",
    "# feature_extractor.trainable = do_fine_tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24744033-9a14-41e5-a899-f3d3dfbbf9db",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-03-25T09:16:40.578778Z",
     "iopub.status.idle": "2023-03-25T09:16:40.579778Z",
     "shell.execute_reply": "2023-03-25T09:16:40.579778Z",
     "shell.execute_reply.started": "2023-03-25T09:16:40.579778Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "do_fine_tuning = False\n",
    "feature_extractor = tf.keras.applications.InceptionResNetV2(\n",
    "                                                include_top=False,\n",
    "                                                weights=\"imagenet\",\n",
    "                                                # input_tensor=None,\n",
    "                                                input_shape=IMG_SHAPE,\n",
    "                                                # pooling=None,\n",
    "                                                # classes=1000,\n",
    "                                                # classifier_activation=\"softmax\",\n",
    "                                                # **kwargs\n",
    ")\n",
    "feature_extractor.trainable = do_fine_tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13757f5d-c17b-4b9a-b61d-0d7e6f547c18",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-03-25T09:16:40.581778Z",
     "iopub.status.idle": "2023-03-25T09:16:40.582778Z",
     "shell.execute_reply": "2023-03-25T09:16:40.582778Z",
     "shell.execute_reply.started": "2023-03-25T09:16:40.582778Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# feature_extractor.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4012270-6acc-4da8-86f3-529c6c4304c9",
   "metadata": {},
   "source": [
    "## Архитектура модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc4802e-235f-45bd-a830-6a899dcbb932",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-03-25T09:16:40.584778Z",
     "iopub.status.idle": "2023-03-25T09:16:40.584778Z",
     "shell.execute_reply": "2023-03-25T09:16:40.584778Z",
     "shell.execute_reply.started": "2023-03-25T09:16:40.584778Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "image_batch, label_batch = next(iter(train_batches))\n",
    "feature_batch = feature_extractor(image_batch)\n",
    "print(feature_batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec3a6f21-26ce-49bf-bba4-ea1fb94a483b",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-03-25T09:16:40.586778Z",
     "iopub.status.idle": "2023-03-25T09:16:40.587778Z",
     "shell.execute_reply": "2023-03-25T09:16:40.587778Z",
     "shell.execute_reply.started": "2023-03-25T09:16:40.587778Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "global_average_layer = tf.keras.layers.GlobalAveragePooling2D()\n",
    "feature_batch_average = global_average_layer(feature_batch)\n",
    "print(feature_batch_average.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dfd99f9-0abe-4ea4-9dc5-bd1ccf724ae3",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-03-25T09:16:40.590778Z",
     "iopub.status.idle": "2023-03-25T09:16:40.591778Z",
     "shell.execute_reply": "2023-03-25T09:16:40.590778Z",
     "shell.execute_reply.started": "2023-03-25T09:16:40.590778Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "prediction_layer = tf.keras.layers.Dense(num_classes, activation='softmax',\n",
    "                                  kernel_regularizer=REGULARIZER\n",
    "                                 )\n",
    "prediction_batch = prediction_layer(feature_batch_average)\n",
    "print(prediction_batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba6b633-b290-4d98-bae0-81435789e312",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-03-25T09:16:40.592778Z",
     "iopub.status.idle": "2023-03-25T09:16:40.593778Z",
     "shell.execute_reply": "2023-03-25T09:16:40.593778Z",
     "shell.execute_reply.started": "2023-03-25T09:16:40.593778Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "inputs = tf.keras.Input(shape=IMG_SHAPE)\n",
    "x = rescale(inputs)\n",
    "x = data_aug(x)\n",
    "x = feature_extractor(x, training=False)\n",
    "x = global_average_layer(x)\n",
    "x = tf.keras.layers.Dropout(DROPOUT_RATE)(x)\n",
    "outputs = prediction_layer(x)\n",
    "model = tf.keras.Model(inputs, outputs)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf46630-24c6-4f56-947d-8448ce96b810",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-03-25T09:16:40.595779Z",
     "iopub.status.idle": "2023-03-25T09:16:40.597779Z",
     "shell.execute_reply": "2023-03-25T09:16:40.597779Z",
     "shell.execute_reply.started": "2023-03-25T09:16:40.597779Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# print(f'Строим модель на базе {MODULE_HANDLE}.')\n",
    "# print(f'Разморозка слоев: {do_fine_tuning}.\\n')\n",
    "\n",
    "# strides = 1\n",
    "# REGULARIZER=tf.keras.regularizers.L1L2(l1=0.0, l2=0.5)\n",
    "\n",
    "# model = tf.keras.Sequential([\n",
    "\n",
    "#             rescale,\n",
    "#             data_aug,\n",
    "\n",
    "#             feature_extractor,\n",
    "\n",
    "#             # tf.keras.layers.Conv2D(32, (3, 3), padding=\"same\",\n",
    "#             #                    strides=strides, activation='relu'),\n",
    "#             # tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "#             # tf.keras.layers.Conv2D(64, (3, 3), padding=\"same\",\n",
    "#             #                    strides=strides, activation='relu'),\n",
    "\n",
    "#             tf.keras.layers.Flatten(),\n",
    "#             tf.keras.layers.Dropout(DROPOUT_RATE),\n",
    "#             tf.keras.layers.BatchNormalization(),\n",
    "#             tf.keras.layers.Dense(num_classes, activation='softmax',\n",
    "#                                   kernel_regularizer=REGULARIZER\n",
    "#                                  )\n",
    "\n",
    "# ], name='pretrained_baseline')\n",
    "\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c1b9f9f-1efc-408f-a31a-f677ec502bd3",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-03-25T09:16:40.599779Z",
     "iopub.status.idle": "2023-03-25T09:16:40.600779Z",
     "shell.execute_reply": "2023-03-25T09:16:40.600779Z",
     "shell.execute_reply.started": "2023-03-25T09:16:40.600779Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(model.trainable_variables)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a80ade24-2949-4531-961f-207a37c25803",
   "metadata": {},
   "source": [
    "## Компиляция"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b872ac0-9c6d-4671-8f65-a64d3cde4807",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-03-25T09:16:40.603779Z",
     "iopub.status.idle": "2023-03-25T09:16:40.604779Z",
     "shell.execute_reply": "2023-03-25T09:16:40.604779Z",
     "shell.execute_reply.started": "2023-03-25T09:16:40.604779Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model.compile(optimizer=tf.keras.optimizers.RMSprop(learning_rate=BASE_LR),\n",
    "#               loss='mse',\n",
    "#               metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "666e6b96-e16b-4285-89bb-12145f451e43",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-03-25T09:16:40.606779Z",
     "iopub.status.idle": "2023-03-25T09:16:40.607779Z",
     "shell.execute_reply": "2023-03-25T09:16:40.606779Z",
     "shell.execute_reply.started": "2023-03-25T09:16:40.606779Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=BASE_LR),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b6b1eed-bc95-447a-baa7-884ea88fb53a",
   "metadata": {},
   "source": [
    "## Обучение модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106b6df6-aa16-4a2a-b049-e64d3afbab41",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-03-25T09:16:40.608779Z",
     "iopub.status.idle": "2023-03-25T09:16:40.609779Z",
     "shell.execute_reply": "2023-03-25T09:16:40.609779Z",
     "shell.execute_reply.started": "2023-03-25T09:16:40.609779Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "hist = model.fit(train_batches,\n",
    "                 epochs=10,\n",
    "                 validation_data=validation_batches,\n",
    "                 callbacks=[early_stopping, lr_schedule])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5187b98-1618-4d4e-aa29-4c48901acc4f",
   "metadata": {},
   "source": [
    "### Визуализация данных по работе алгоритма"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a9625b-8620-4b70-84a5-06ab5410c2a9",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-03-25T09:16:40.618780Z",
     "iopub.status.idle": "2023-03-25T09:16:40.621780Z",
     "shell.execute_reply": "2023-03-25T09:16:40.620780Z",
     "shell.execute_reply.started": "2023-03-25T09:16:40.620780Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "val_acc_viz(hist, len(hist.history['accuracy']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48b331e2-57f6-4549-a5b6-c0cba6f794d7",
   "metadata": {},
   "source": [
    "### Предсказание модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "968d2f67-4b8c-4222-8e46-0510bfc7ad88",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-03-25T09:16:40.627780Z",
     "iopub.status.idle": "2023-03-25T09:16:40.628780Z",
     "shell.execute_reply": "2023-03-25T09:16:40.628780Z",
     "shell.execute_reply.started": "2023-03-25T09:16:40.628780Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "show_predictions(model, visualization=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "845d62c3-c720-43d8-bb23-fbf350a7ddd2",
   "metadata": {},
   "source": [
    "### Матрица ошибок"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a0328f-8053-410b-9231-97d4918a0beb",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-03-25T09:16:40.630781Z",
     "iopub.status.idle": "2023-03-25T09:16:40.632781Z",
     "shell.execute_reply": "2023-03-25T09:16:40.632781Z",
     "shell.execute_reply.started": "2023-03-25T09:16:40.632781Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "confusion_matrix(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab6034b-2b23-44f1-bc13-af9ac3ae0d6e",
   "metadata": {},
   "source": [
    "### Вывод"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d394456-1d56-4dc5-a7ea-8643aa639de9",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-03-25T09:16:40.635781Z",
     "iopub.status.idle": "2023-03-25T09:16:40.636781Z",
     "shell.execute_reply": "2023-03-25T09:16:40.636781Z",
     "shell.execute_reply.started": "2023-03-25T09:16:40.636781Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "val_acc_best = np.max(hist.history['val_accuracy'])\n",
    "val_auc_best = np.max(hist.history['val_PR_AUC'])\n",
    "model_best_results = round(val_acc_best, 2), round(val_auc_best, 2)\n",
    "\n",
    "print(f'val_accuracy: {model_best_results[0]}')\n",
    "print(f'val_PR_AUC: {model_best_results[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0fdb023-8b2e-4311-863f-4b541eb7dc73",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-03-25T09:16:40.639781Z",
     "iopub.status.idle": "2023-03-25T09:16:40.640781Z",
     "shell.execute_reply": "2023-03-25T09:16:40.640781Z",
     "shell.execute_reply.started": "2023-03-25T09:16:40.640781Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# сохраним данные о модели\n",
    "model_pretrained = model\n",
    "hist_pretrained = hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff2a7bb-1f46-4704-b02e-264a491cea87",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-03-25T09:16:40.642781Z",
     "iopub.status.idle": "2023-03-25T09:16:40.643781Z",
     "shell.execute_reply": "2023-03-25T09:16:40.643781Z",
     "shell.execute_reply.started": "2023-03-25T09:16:40.643781Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# stat_3['SGD 1_layer_1024'] = model_best_results[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361713fb-df95-4d89-94c5-c2a22a0aa70c",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-03-25T09:16:40.645781Z",
     "iopub.status.idle": "2023-03-25T09:16:40.647782Z",
     "shell.execute_reply": "2023-03-25T09:16:40.646781Z",
     "shell.execute_reply.started": "2023-03-25T09:16:40.646781Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# stat_3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5743fe51-edd9-419b-8057-643ae7463f8a",
   "metadata": {},
   "source": [
    "## Разморозка слоев"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cef6276-033b-4b79-babf-4dbfe8ead897",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-03-25T09:16:40.649782Z",
     "iopub.status.idle": "2023-03-25T09:16:40.650782Z",
     "shell.execute_reply": "2023-03-25T09:16:40.650782Z",
     "shell.execute_reply.started": "2023-03-25T09:16:40.650782Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "do_fine_tuning = True\n",
    "feature_extractor.trainable = do_fine_tuning\n",
    "\n",
    "print(f'Разморозка слоев: {do_fine_tuning}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bd1ce76-5902-4983-adf1-40fabf0ef3d8",
   "metadata": {},
   "source": [
    "Посмотрим на количество слоев в предобученной модели:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b295486-2d73-41cc-91bc-d4407208484a",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-03-25T09:16:40.652782Z",
     "iopub.status.idle": "2023-03-25T09:16:40.653782Z",
     "shell.execute_reply": "2023-03-25T09:16:40.653782Z",
     "shell.execute_reply.started": "2023-03-25T09:16:40.653782Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# с какого слоя мы размораживаем модель\n",
    "fine_tune_at = 600\n",
    "\n",
    "# Заморозим все остальные слои\n",
    "for layer in feature_extractor.layers[:fine_tune_at+1]:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc84b27-e6b6-4165-a5b7-28e41dc0e2dc",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-03-25T09:16:40.656782Z",
     "iopub.status.idle": "2023-03-25T09:16:40.658782Z",
     "shell.execute_reply": "2023-03-25T09:16:40.657782Z",
     "shell.execute_reply.started": "2023-03-25T09:16:40.657782Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"Number of layers in the feature extractor: \", len(feature_extractor.layers))\n",
    "print(\"Trainable layers in the feature extractor: \", len(feature_extractor.trainable_variables))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7441c1eb-aca2-4a60-afeb-ae9f353eb08f",
   "metadata": {},
   "source": [
    "## Компиляция"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adaaf1fe-813e-4835-b251-f6d26109cb79",
   "metadata": {},
   "source": [
    "Теперь необходимо скомпилировать нашу уже обученную на предыдущем этапе модель, чтобы изменения были применены."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5261b42d-cf28-41d4-9bb5-84d9646173d5",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-03-25T09:16:40.660782Z",
     "iopub.status.idle": "2023-03-25T09:16:40.662782Z",
     "shell.execute_reply": "2023-03-25T09:16:40.661782Z",
     "shell.execute_reply.started": "2023-03-25T09:16:40.661782Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model.compile(optimizer=tf.keras.optimizers.RMSprop(),\n",
    "#               loss='mse',\n",
    "#               metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a1e533-47cb-4273-8770-854931d4299a",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-03-25T09:16:40.664783Z",
     "iopub.status.idle": "2023-03-25T09:16:40.666783Z",
     "shell.execute_reply": "2023-03-25T09:16:40.665783Z",
     "shell.execute_reply.started": "2023-03-25T09:16:40.665783Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=BASE_LR),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd2fb4f3-e4a9-4d74-92eb-835c29629cca",
   "metadata": {},
   "source": [
    "## Архитектура модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2962241-235b-4736-9511-cab8fe30d3ef",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-03-25T09:16:40.686784Z",
     "iopub.status.idle": "2023-03-25T09:16:40.687784Z",
     "shell.execute_reply": "2023-03-25T09:16:40.687784Z",
     "shell.execute_reply.started": "2023-03-25T09:16:40.687784Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8624c95-8ee7-41bd-ad3c-df8a87582063",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-03-25T09:16:40.689784Z",
     "iopub.status.idle": "2023-03-25T09:16:40.689784Z",
     "shell.execute_reply": "2023-03-25T09:16:40.689784Z",
     "shell.execute_reply.started": "2023-03-25T09:16:40.689784Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(model.trainable_variables)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f81bece-15ae-4739-9768-bc87241603c0",
   "metadata": {},
   "source": [
    "## Обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d87e3d2-08d2-4332-b5e8-1c0a11820012",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-03-25T09:16:40.691784Z",
     "iopub.status.idle": "2023-03-25T09:16:40.693784Z",
     "shell.execute_reply": "2023-03-25T09:16:40.692784Z",
     "shell.execute_reply.started": "2023-03-25T09:16:40.692784Z"
    }
   },
   "outputs": [],
   "source": [
    "hist = model.fit(train_batches,\n",
    "                 epochs=EPOCHS,\n",
    "                 validation_data=validation_batches,\n",
    "                 callbacks=[early_stopping, lr_schedule])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489282ae-42a4-4829-94e2-448b5d5adcf5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71538fb8-8b31-43bf-9846-ccbe2351061f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "901512de-027c-474c-993a-da2b0e9008e8",
   "metadata": {},
   "source": [
    "### Визуализация данных по работе алгоритма"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad404aa-2ec4-4190-a561-15218af32d90",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-03-25T09:16:40.695784Z",
     "iopub.status.idle": "2023-03-25T09:16:40.695784Z",
     "shell.execute_reply": "2023-03-25T09:16:40.695784Z",
     "shell.execute_reply.started": "2023-03-25T09:16:40.695784Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "val_acc_viz(hist, len(hist.history['accuracy']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7568b13e-504c-4130-9d0c-5ba47d0bc361",
   "metadata": {},
   "source": [
    "### Предсказание модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3913f98-8807-4fd4-af1d-aa6050fa127a",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-03-25T09:16:40.697784Z",
     "iopub.status.idle": "2023-03-25T09:16:40.697784Z",
     "shell.execute_reply": "2023-03-25T09:16:40.697784Z",
     "shell.execute_reply.started": "2023-03-25T09:16:40.697784Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "show_predictions(model, visualization=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f90998df-367b-433e-bc4c-b48f7f1b6f5d",
   "metadata": {},
   "source": [
    "### Матрица ошибок"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc7abc94-1861-434e-a41c-0def1bdc7700",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-03-25T09:16:40.699785Z",
     "iopub.status.idle": "2023-03-25T09:16:40.700785Z",
     "shell.execute_reply": "2023-03-25T09:16:40.700785Z",
     "shell.execute_reply.started": "2023-03-25T09:16:40.700785Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "confusion_matrix(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e54888-4d4d-491d-b6db-a9d8c00c18df",
   "metadata": {},
   "source": [
    "### Вывод"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e104c3-8dab-4af1-92f3-c83404855b5e",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-03-25T09:16:40.702785Z",
     "iopub.status.idle": "2023-03-25T09:16:40.703785Z",
     "shell.execute_reply": "2023-03-25T09:16:40.702785Z",
     "shell.execute_reply.started": "2023-03-25T09:16:40.702785Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "val_acc_best = np.max(hist.history['val_accuracy'])\n",
    "val_auc_best = np.max(hist.history['val_PR_AUC'])\n",
    "model_best_results = round(val_acc_best, 2), round(val_auc_best, 2)\n",
    "\n",
    "print(f'val_accuracy: {model_best_results[0]}')\n",
    "print(f'val_PR_AUC: {model_best_results[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "687d7bfb-87db-437d-acb3-1dabf92825b6",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-03-25T09:16:40.704785Z",
     "iopub.status.idle": "2023-03-25T09:16:40.705785Z",
     "shell.execute_reply": "2023-03-25T09:16:40.704785Z",
     "shell.execute_reply.started": "2023-03-25T09:16:40.704785Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# сохраним данные о модели\n",
    "model_32 = model\n",
    "hist_32 = hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f19d3632-0142-45d0-bc83-81e651053653",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-03-25T09:16:40.706785Z",
     "iopub.status.idle": "2023-03-25T09:16:40.707785Z",
     "shell.execute_reply": "2023-03-25T09:16:40.707785Z",
     "shell.execute_reply.started": "2023-03-25T09:16:40.707785Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "stat_3['SGD 1_layer_1024'] = model_best_results[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa2d6c4f-d565-46cf-a49f-e1cb29b71ebc",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-03-25T09:16:40.709785Z",
     "iopub.status.idle": "2023-03-25T09:16:40.712785Z",
     "shell.execute_reply": "2023-03-25T09:16:40.709785Z",
     "shell.execute_reply.started": "2023-03-25T09:16:40.709785Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "stat_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae3556b-cc7a-4bde-b1b4-733baf35059d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca729e91-8c7e-4324-8fd2-c0f118c560cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cc5f50c8-6a3b-44a9-be95-4a073ec7d97b",
   "metadata": {},
   "source": [
    "# <b>Использованные источники и литература</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa86878-d47b-40fd-b2d8-e7b105766867",
   "metadata": {},
   "source": [
    "**Курсы**\n",
    "\n",
    "1. Holbrook R. Intro to Deep Learning // https://www.kaggle.com/learn/intro-to-deep-learning\n",
    "1. Moroney L. Device-based Models with TensorFlow Lite // https://www.coursera.org/learn/device-based-models-tensorflow\n",
    "\n",
    "**Статьи**\n",
    "1. Confusion Matrix // https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html \n",
    "1. Load and preprocess images // https://www.tensorflow.org/tutorials/load_data/images\n",
    "1. Module: tf.data.Dataset // https://www.tensorflow.org/api_docs/python/tf/data/Dataset\n",
    "1. Module: tf.keras.applications.mobilenet_v2 // https://www.tensorflow.org/api_docs/python/tf/keras/applications/mobilenet_v\n",
    "1. Transfer learning and fine-tuning // https://www.tensorflow.org/tutorials/images/transfer_learning\n",
    "1. Transfer learning and fine-tuning // https://keras.io/guides/transfer_learning/\n",
    "1. Lakhani N.D. Statistical Evaluation Metrics // https://iust-projects.ir/post/minidm01/\n",
    "\n",
    "**Форумы**\n",
    "1. StackOverflow // https://stackoverflow.com/\n",
    "1. GitHub // https://github.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e165e0-9cee-4b84-97cf-83c8e0b70eef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b10b6c-759e-41e4-af15-97d6aa09d65b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d026a800-1692-4a52-9f23-940098c137dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2299f15a-8499-46d1-9221-aac6dee8c97e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef2f7ab-014e-4616-9d35-2f372c9cb4ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c2bb5d-1059-4555-aea0-c988b83a597c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a748c72b-09cd-4a7c-9f96-f1eb5be1335e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faad3522-f964-4b4e-bce0-ab8f4d0952ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ccccbfd-051b-48e1-a48f-526c2051468b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e977231-8f90-4a96-857b-78dc342505d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8680132-2fb3-43cb-99ed-d53d7ed204ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbbe6682-3b44-45c7-ba62-c9b90e70acbe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c7f705c-dfe6-45d5-a98e-eaac2230e2a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb27491-4261-4b36-86e2-60fce0d6044d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "559986fb-59ac-4ae7-801f-5cef17090045",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a04176-0cfb-4e5d-999d-6704b44d7b5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d43551-a951-4744-be76-c37f3d50f092",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a22a22-4873-431e-8e03-8f1c7711c820",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "087a0931-6070-46e8-a26a-51da8cf41af2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce19c4c-d8a3-4979-97c9-dca65ffb9345",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b059d1d0-fce1-4f5e-9e4a-4d384e9e9749",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c3c1b81-7f5e-4d69-af33-4d35b0fe4e83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e852b6-7e57-402a-8f92-c35d851ac272",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d22d38c-aa01-450f-9af8-8578c65df262",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f8b2f62-393f-4846-8570-442a3ff8aa53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a7ef516-79fb-47dc-b1a3-71465d3fa8c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d126fc97-5567-4531-92bc-e86e2c0ac206",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd5d04e-39ab-4ea6-b55e-5eb6399b475a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e991462-f0f4-4276-b978-164fda6cf92c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c90e63b0-d9db-4dc2-8f81-103ef918eac8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e4c78f-63b4-4c62-9e68-1628fe89ffd7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ce90fc-74e2-4711-a71d-5032b091293c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e9c5be0-ad5f-428a-9928-24370b977e0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b840ad-5df9-4fa1-b36f-2aa2f5e1e92e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16fb0e1b-065f-4675-812b-dd0be1384a43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b59e6d96-467e-461c-b9d4-67124d737205",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c762a82-792c-4223-84b8-b66df9edaf82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ac7583-9ef0-42f0-b631-df48598c8c58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db0e7f3-4abf-4255-8086-bc8be5d5a7bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf15848-9814-46be-855b-4dc94750cfd0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65c66a1-d78f-408a-84f2-55859d0a288a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a118753-33db-478a-896e-f650c41a750e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a7b9b74-fe33-4792-8902-17fda60a3586",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c301553d-96b6-4e2b-ae57-80100bbe125f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c21bf90a-aac2-4b4c-a953-6d218f67f636",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e8a92f-bda3-43c7-a45f-c933d0c4cd47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd0af45-93b8-4366-b23c-ca0ce6d9f638",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3768588-65c3-4f42-a9fd-b5bf54a02617",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28833416-bbbb-4531-bb69-7e13aec41b00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aac5c4f-81bf-49fe-8e7f-9b53050b70b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6010aa18-30dd-4b81-b505-ffbf5027c23d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f26414a3-ed02-4d6c-989f-12b71dbd4b82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "644f5a8b-db48-4594-a998-a7603d327767",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53eb9f3c-4a65-47b2-9160-890e5a2d702e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8cd7824-23d6-4ae3-a288-4c2cfa73f674",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c15ffb33-e6e8-410a-a366-c9431a61c831",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b2a709-922e-42e6-8f0b-5c8e00cc1b97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4bae923-8217-4c3b-82a5-fe1fa7cd9a6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c1cc72-c847-4641-be88-9c16335656de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d17faa-ff24-4a13-aac0-a52b72145fe0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d413ce14-17ec-45df-88d0-b9b19df03eed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf7c9d3-b95a-4b7e-909b-458aec2a1bff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "507c8b22-c786-4e87-99eb-60b11ec2e16f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48fce45b-6686-4a7e-babd-1ea35cba4a98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b31c47-d79e-4649-9904-b09b119f80b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e17429-cf38-477b-a041-24fb00c8c901",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef42f00-e93b-4b3a-9a39-7cc340f272f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4207e10-a3cf-4913-8b7f-65ecc809bff2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b84bf1ab-bd9b-42fb-81b9-6916ca90aaf2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e47e3a83-73e6-4844-85ac-bc859a699dde",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42ed695-d98e-47f7-b9ae-fb88483d59ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb6e606-e581-4be3-81df-fa095fdafa59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b6a86a-d0bb-4091-98a1-6c373a9a731b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17401c0b-7933-4b56-b709-894a8727ab52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af855bb-a02d-46d2-b670-0b094457357d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54839037-d44b-41a6-a8ad-8c59c3a740a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79124c35-71e2-4d0c-b89b-0472652115d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c49fe7-478f-42ef-aea3-26701dbc1cf0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb8473fd-047e-48e2-8390-5590d5027059",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c986946-2ea7-4c59-8f96-72e86a19789a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a1c134-6b87-4381-99f5-23a7f3e489bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b2c295d-1887-42b8-ba96-34771229611e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8675ea70-2a9d-4cd0-b140-a082d317b11e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ccc398-717a-435d-aad8-41dad67085d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "871f9a0a-ea80-45a0-82e0-84f61994cb64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aede319-0122-4785-94ed-65539ada7285",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a98d82-4087-4307-9b6e-d9b0ee3844f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca121a16-40d7-48bd-b334-47f9b882d667",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f4f6e4-08d0-48f3-9ae0-2047f2e940f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba60fd11-e2d6-4abf-b1cc-c3825ca47778",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e68ac5-e32a-4c42-a894-7a7420dd326c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a46765-300b-48a9-9740-2ec68381a031",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "245f1669-a516-43ea-8c06-3db8349f926d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc83a6b9-5009-4d03-9531-ea57c40a7416",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e1aec72-6723-4d7b-a73f-e9d12d45c477",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41222c87-1cec-448f-9ea6-45c0eadb0010",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db462e1-e50f-4af0-8e12-9bf7ea4d9473",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e5065c-4885-4165-b948-0170707c2f4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e207fd27-6e0d-4fc8-ab10-785f41d6412a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a435965-2f7e-4f1d-bda9-697f53ef4071",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c0a26a7-fcfb-4a2d-b9a3-d52906e3774b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a35aa2-87b4-44db-a5cb-dbeb3cb02f36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7367c87-f9de-4ec1-bf57-d8a75e4eec4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e395624f-5f3f-4a65-b599-03d67e322682",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da65a8cb-82bf-42a5-a029-9e0f56036abf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59216da7-b87c-466e-9eec-ab763ce917d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e437ff4a-2f14-4df8-b5d2-921d7e0ee204",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b350db1-c210-498c-b0ab-46147b9446a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ee29e4-f78f-465f-b3a8-c7f2ad27842b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de4ec7d-a5a8-4b7e-b313-7fcd6c7260a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc34e0b-9d34-454f-aaad-0299429a1c6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c97e79fc-2af8-4dcd-882e-f282a15d8632",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a336bf-2226-4c75-b584-65d970ed28da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd505e29-2c2f-456f-988d-1a0af237c3a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ce2573-594d-484b-a1d8-8ce5799ecf88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54655d65-b519-45d2-a141-cde4cf456117",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afca36b3-36a6-4991-8cd4-60fb9c26314c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a6ef7b3-28bb-40ed-97b9-2ef094bfb962",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa3a8cc-f470-42da-8604-a08e1489b149",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99975145-be9e-443d-b969-8a3f04d97a42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b692e6-0826-4e67-a3d8-7c0837c1f399",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c37b3b-3543-4022-b55e-fcd40a4f5d43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78596ff9-4421-4d8f-a104-795375bf3bc8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fecf69b-bc70-4915-8f5c-a252dfda2509",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e90c1e4-27d4-47d7-b3c7-101c0eb41a97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f595b0-2144-4e0e-943f-e9ddae22830e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a7b36d-5139-4a8a-a322-050c058d3ab2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9690580-0584-45a7-9fdc-7a67853804a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef74326f-ffa9-4f8a-b3ad-22d1c0addf79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af95ece7-9f3d-40b6-b740-d361d65e0af9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a35c42-1bf9-413b-9b5d-217a1b0af3d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65cf26e9-6f13-45f9-b1a9-e700f282ae4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6547d85c-a1a0-447e-983e-2eb7f3be6676",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea12005d-f7ce-49aa-9f26-50d6fd81feee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d1600d-b121-48ab-a9ab-48cb804253f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655cebc0-2d37-47bf-9b16-31347875b01a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "769135ce-b5eb-48c4-8fbd-846446231496",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef1b901-1353-48b3-998d-8b2b70ebf68b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc17332-4c1f-47c6-947c-4ea6f41aa2b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47715098-c291-4003-acfe-a2818cc7c02b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b0fc9c-4397-4dc4-93d0-377934bea96f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a9969d-990e-4a48-8919-be67bc7f1ccf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52559b27-3c5e-4786-813f-4121ae6a0a94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f94fab-1edd-4de3-b0ea-5538f68139fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe96a11-a98d-4c9f-ad52-1647077aaf8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be30f33a-8fd1-4c26-9bba-ba0628b89b85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f047c876-b66f-40d3-8f1f-e4828ebbf546",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf2696e-d953-45c6-b410-04a1183ccb26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e43d3852-4986-45d7-b3ea-f18ac8b045a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c32943-13b6-45d9-87eb-248583cb8bc0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f51115-d334-4272-ac3b-ce69a7342f07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db2a787f-7e37-4ea9-9bbe-0683c47f74ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f7ad4c-1118-4ff1-96d5-3ff7e6c5a64c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "714556ab-ce6a-4949-b003-0f5ef6eed5b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eed3d9b-9e7c-4f05-afb9-e0e6f8a12f0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b57fca5-ab51-414c-bc88-2c47185f0521",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e161fd58-244f-4110-a928-f46d41179e88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c235889f-549e-4d1e-a53a-84963e31ad19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb81de27-d681-48d0-b2d7-50c517437111",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6bd4a66-dc55-4931-958c-580c48cff3f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "932c5002-8ce0-4c23-bd9d-8f905f928330",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "967f8c10-d506-445f-b65d-12fd789bdf3e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv38",
   "language": "python",
   "name": "venv38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
